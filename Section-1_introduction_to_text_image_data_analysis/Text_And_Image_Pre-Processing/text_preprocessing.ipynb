{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Pre-Processing Using nltk Library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Mining:\n",
    "\n",
    " - For effectively handling of text data, we require intelligent algorithm to retrieve relevant information from the data repositories.\n",
    "The retrieval of information is called text mining.\n",
    "- Difference between data mining and text mining :\n",
    "  * Data Mining - Applied on Structured Data and relational data.\n",
    "  * Text Mining - Applied on unstructured data and semi-structure data.Text mining, also known as text data mining, is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights for further analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE CASES:\n",
    "\n",
    " 1. TEXT MINING FOR LONG DOCUMENTS/SPEECH/RESUME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Representation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ### Reading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "\n",
    "data = docx2txt.process('/Users/hackthebox/Downloads/Machine_Learning_for_Text_And_Image_Data_Analysis/Section-1_introduction_to_text_image_data_analysis/Text_And_Image_Pre-Processing/sample3.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open('/Users/hackthebox/Downloads/Machine_Learning_for_Text_And_Image_Data_Analysis/Section-1_introduction_to_text_image_data_analysis/Text_And_Image_Pre-Processing/agatha_complete.txt','r')\n",
    "textdata = textfile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the punctuation marks from string module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different punctuation marks in string module: \n",
      " !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(\"Different punctuation marks in string module: \\n\",punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Original Document of Text Mining ----------\n",
      "The ABC Murders – 1936\n",
      "The Adventure of the Christmas Pudding – 1960\n",
      "After the Funeral (also known as Funerals are Fatal) – 1953\n",
      "And Then There Were None (also known as Ten Little Indians and Ten Little Niggers – 1939\n",
      "Appointment with Death – 1938\n",
      "At Bertram’s Hotel – 1965\n",
      "The Big Four – 1927\n",
      "The Body in the Library – 1942\n",
      "By the Pricking of my Thumbs – 1968\n",
      "Cards on the Table – 1936\n",
      "A Caribbean Mystery – 1964\n",
      "Cat Among the Pigeons – 1959\n",
      "The Clocks – 1963\n",
      "Crooked House – 1949\n",
      "Curtain: Poirot’s Last Case – 1975\n",
      "Dead Man’s Folly – 1956\n",
      "Death Comes At The End – 1945\n",
      "Death in the Clouds (also known as Death In The Air) – 1935\n",
      "Death on the Nile – 1937\n",
      "Destination Unknown (also known as So Many Steps to Death) – 1954\n",
      "Double Sin and Other Stories – 1961\n",
      "Dumb Witness (also known as Poirot Loses a Client) – 1937\n",
      "Elephants Can Remember – 1972\n",
      "Endless Night – 1967\n",
      "Evil Under the Sun – 1941\n",
      "Five Little Pigs (also known as Murder In Retrospect) – 1943\n",
      "4.50 from Paddington (also known as What Mrs. McGillicuty Saw) – 1957\n",
      "The Golden Ball and Other Stories – 1971\n",
      "Halloween Party – 1969\n",
      "Hercules Poirot’s Christmas (also known as A Holiday for Murder) – 1938\n",
      "Hickory Dickory Death – 1955\n",
      "The Hollow (also known as Murder After Hours) – 1946\n",
      "The Hound of Death – 1933\n",
      "The Labours of Hercules – 1947\n",
      "The Listerdale Mystery Morterblumen – 1934\n",
      "Lord Edgware Dies (also known as Thirteen At Dinner) – 1933\n",
      "The Man in the Brown Suit (also known as Mystery of the Mill House) – 1924\n",
      "The Mirror Crack’d from Side to Side (also known as The Mirror Crack’d) – 1962\n",
      "Miss Marple’s Final Cases – 1979\n",
      "The Mousetrap and Other Stories (also known as 3 Blind Mice) 1950\n",
      "The Moving Finger – 1943\n",
      "Mrs. McGinty’s Dead – 1952\n",
      "The Murder in the Vicarage – 1930\n",
      "Murder in Mesopotamia – 1936\n",
      "Murder in the Mews (also known as Dead Man’s Mirror) – 1937\n",
      "A Murder is Announced – 1950\n",
      "Murder is Easy Easy to Kill – 1939\n",
      "The Murder of Roger Ackroyd – 1926\n",
      "Murder on the Links – 1923\n",
      "Murder on the Orient Express (also known as Murder on the Calais Coach) – 1934\n",
      "The Mysterious Affair at Styles – 1920\n",
      "The Mysterious Mr. Quin – 1930\n",
      "The Mystery of the Blue Train – 1928\n",
      "Nemesis – 1971\n",
      "N or M? – 1941\n",
      "One, Two, Buckle My Shoe (also known as The Patriotic Murders) – 1940\n",
      "Ordeal by Innocence – 1958\n",
      "The Pale Horse – 1961\n",
      "Parker Pyne Investigates (also known as Mr. Parker Pyne, Detective) – 1934\n",
      "Partners in Crime – 1929\n",
      "Passenger to Frankfurt – 1970\n",
      "Peril at End House – 1932\n",
      "A Pocket Full of Rye – 1953\n",
      "Poirot Investigates – 1924\n",
      "Poirot’s Early Cases – 1974\n",
      "Postern of Fate – 1973\n",
      "Problem at Pollensa Bay – 19??\n",
      "The Regatta Mystery – 1939\n",
      "Sad Cypress – 1940\n",
      "The Secret Adversary – 1922\n",
      "The Secret of Chimneys – 1925\n",
      "The Seven Dials Mystery – 1929\n",
      "The Sittaford Mystery (also known as The Murder At Hazelmoor) – 1931\n",
      "Sleeping Murder – 1976\n",
      "Sparkling Cyanide (also known as Remembered Death) – 1945\n",
      "Taken at the Flood (also known as There Is a Tide…) – 1948\n",
      "They Came to Baghdad – 1951\n",
      "They Do It With Mirrors (also known as Murder with Mirrors) – 1952\n",
      "Third Girl – 1966\n",
      "The Thirteen Problems (also known as The Tuesday Club Murders – 1932\n",
      "Three-Act Tragedy (also known as Murder In Three Acts) – 1935\n",
      "Towards Zero – 1944\n",
      "The Underdog and Other Stories – 1951\n",
      "Witness for the Prosecution and Other Stories – 1948\n",
      "Why Didn’t They Ask Evans (also known as The Boomerang Clue) – 1934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------ Original Document of Text Mining ----------\")\n",
    "print(textdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of translate(),lower() and split() function to remove punctuation marks in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Converting document into lower case words -----------\n",
      "['the', 'abc', 'murders', '–', '1936+the', 'adventure', 'of', 'the', 'christmas', 'pudding', '–', '1960+after', 'the', 'funeral', '(also', 'known', 'as', 'funerals', 'are', 'fatal)', '–', '1953+and', 'then', 'there', 'were', 'none', '(also', 'known', 'as', 'ten', 'little', 'indians', 'and', 'ten', 'little', 'niggers', '–', '1939+appointment', 'with', 'death', '–', '1938+at', 'bertram’s', 'hotel', '–', '1965+the', 'big', 'four', '–', '1927+the', 'body', 'in', 'the', 'library', '–', '1942+by', 'the', 'pricking', 'of', 'my', 'thumbs', '–', '1968+cards', 'on', 'the', 'table', '–', '1936+a', 'caribbean', 'mystery', '–', '1964+cat', 'among', 'the', 'pigeons', '–', '1959+the', 'clocks', '–', '1963+crooked', 'house', '–', '1949+curtain:', 'poirot’s', 'last', 'case', '–', '1975+dead', 'man’s', 'folly', '–', '1956+death', 'comes', 'at', 'the', 'end', '–', '1945+death', 'in', 'the', 'clouds', '(also', 'known', 'as', 'death', 'in', 'the', 'air)', '–', '1935+death', 'on', 'the', 'nile', '–', '1937+destination', 'unknown', '(also', 'known', 'as', 'so', 'many', 'steps', 'to', 'death)', '–', '1954+double', 'sin', 'and', 'other', 'stories', '–', '1961+dumb', 'witness', '(also', 'known', 'as', 'poirot', 'loses', 'a', 'client)', '–', '1937+elephants', 'can', 'remember', '–', '1972+endless', 'night', '–', '1967+evil', 'under', 'the', 'sun', '–', '1941+five', 'little', 'pigs', '(also', 'known', 'as', 'murder', 'in', 'retrospect)', '–', '1943+4.50', 'from', 'paddington', '(also', 'known', 'as', 'what', 'mrs.', 'mcgillicuty', 'saw)', '–', '1957+the', 'golden', 'ball', 'and', 'other', 'stories', '–', '1971+halloween', 'party', '–', '1969+hercules', 'poirot’s', 'christmas', '(also', 'known', 'as', 'a', 'holiday', 'for', 'murder)', '–', '1938+hickory', 'dickory', 'death', '–', '1955+the', 'hollow', '(also', 'known', 'as', 'murder', 'after', 'hours)', '–', '1946+the', 'hound', 'of', 'death', '–', '1933+the', 'labours', 'of', 'hercules', '–', '1947+the', 'listerdale', 'mystery', 'morterblumen', '–', '1934+lord', 'edgware', 'dies', '(also', 'known', 'as', 'thirteen', 'at', 'dinner)', '–', '1933+the', 'man', 'in', 'the', 'brown', 'suit', '(also', 'known', 'as', 'mystery', 'of', 'the', 'mill', 'house)', '–', '1924+the', 'mirror', 'crack’d', 'from', 'side', 'to', 'side', '(also', 'known', 'as', 'the', 'mirror', 'crack’d)', '–', '1962+miss', 'marple’s', 'final', 'cases', '–', '1979+the', 'mousetrap', 'and', 'other', 'stories', '(also', 'known', 'as', '3', 'blind', 'mice)', '1950+the', 'moving', 'finger', '–', '1943+mrs.', 'mcginty’s', 'dead', '–', '1952+the', 'murder', 'in', 'the', 'vicarage', '–', '1930+murder', 'in', 'mesopotamia', '–', '1936+murder', 'in', 'the', 'mews', '(also', 'known', 'as', 'dead', 'man’s', 'mirror)', '–', '1937+a', 'murder', 'is', 'announced', '–', '1950+murder', 'is', 'easy', 'easy', 'to', 'kill', '–', '1939+the', 'murder', 'of', 'roger', 'ackroyd', '–', '1926+murder', 'on', 'the', 'links', '–', '1923+murder', 'on', 'the', 'orient', 'express', '(also', 'known', 'as', 'murder', 'on', 'the', 'calais', 'coach)', '–', '1934+the', 'mysterious', 'affair', 'at', 'styles', '–', '1920+the', 'mysterious', 'mr.', 'quin', '–', '1930+the', 'mystery', 'of', 'the', 'blue', 'train', '–', '1928+nemesis', '–', '1971+n', 'or', 'm?', '–', '1941+one,', 'two,', 'buckle', 'my', 'shoe', '(also', 'known', 'as', 'the', 'patriotic', 'murders)', '–', '1940+ordeal', 'by', 'innocence', '–', '1958+the', 'pale', 'horse', '–', '1961+parker', 'pyne', 'investigates', '(also', 'known', 'as', 'mr.', 'parker', 'pyne,', 'detective)', '–', '1934+partners', 'in', 'crime', '–', '1929+passenger', 'to', 'frankfurt', '–', '1970+peril', 'at', 'end', 'house', '–', '1932+a', 'pocket', 'full', 'of', 'rye', '–', '1953+poirot', 'investigates', '–', '1924+poirot’s', 'early', 'cases', '–', '1974+postern', 'of', 'fate', '–', '1973+problem', 'at', 'pollensa', 'bay', '–', '19??+the', 'regatta', 'mystery', '–', '1939+sad', 'cypress', '–', '1940+the', 'secret', 'adversary', '–', '1922+the', 'secret', 'of', 'chimneys', '–', '1925+the', 'seven', 'dials', 'mystery', '–', '1929+the', 'sittaford', 'mystery', '(also', 'known', 'as', 'the', 'murder', 'at', 'hazelmoor)', '–', '1931+sleeping', 'murder', '–', '1976+sparkling', 'cyanide', '(also', 'known', 'as', 'remembered', 'death)', '–', '1945+taken', 'at', 'the', 'flood', '(also', 'known', 'as', 'there', 'is', 'a', 'tide…)', '–', '1948+they', 'came', 'to', 'baghdad', '–', '1951+they', 'do', 'it', 'with', 'mirrors', '(also', 'known', 'as', 'murder', 'with', 'mirrors)', '–', '1952+third', 'girl', '–', '1966+the', 'thirteen', 'problems', '(also', 'known', 'as', 'the', 'tuesday', 'club', 'murders', '–', '1932+three-act', 'tragedy', '(also', 'known', 'as', 'murder', 'in', 'three', 'acts)', '–', '1935+towards', 'zero', '–', '1944+the', 'underdog', 'and', 'other', 'stories', '–', '1951+witness', 'for', 'the', 'prosecution', 'and', 'other', 'stories', '–', '1948+why', 'didn’t', 'they', 'ask', 'evans', '(also', 'known', 'as', 'the', 'boomerang', 'clue)', '–', '1934+']\n",
      "The number of words in the document are:  560\n"
     ]
    }
   ],
   "source": [
    "word_doc = textdata.translate(punctuation).lower().split()\n",
    "print(\"---------- Converting document into lower case words -----------\")\n",
    "print(word_doc)\n",
    "print(\"The number of words in the document are: \",len(word_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of counter() function to display the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most Common words in document are:\n",
      "('–', 84)\n",
      "('the', 27)\n",
      "('(also', 24)\n",
      "('known', 24)\n",
      "('as', 24)\n",
      "('of', 10)\n",
      "('in', 10)\n",
      "('murder', 10)\n",
      "('mystery', 7)\n",
      "('at', 7)\n",
      "('and', 6)\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter(word_doc)\n",
    "print(\"The most Common words in document are:\")\n",
    "for word in word_counts.most_common(11):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    " \n",
    "  * Data cleaning is an important phase before applying any algorithm on text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ### Program related to data cleaning\n",
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining number of letters in the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of letters in the original document: 3351\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of letters in the original document:\",len(textdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unwanted characters from document using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdoc = re.sub(r'[^a-zA-Z0-9\\s]','',textdata,re.I | re.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining number of letters in the new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of letters after removing unwanted characters:  3196\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of letters after removing unwanted characters: \",len(textdoc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting all the words to lower case for exact determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdoc = textdoc.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing leading and trailing spaces from document using strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdoc = textdoc.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new document is: \n",
      " the abc murders  1936\n",
      "the adventure of the christmas pudding  1960\n",
      "after the funeral also known as funerals are fatal  1953\n",
      "and then there were none also known as ten little indians and ten little niggers  1939\n",
      "appointment with death  1938\n",
      "at bertrams hotel  1965\n",
      "the big four  1927\n",
      "the body in the library  1942\n",
      "by the pricking of my thumbs  1968\n",
      "cards on the table  1936\n",
      "a caribbean mystery  1964\n",
      "cat among the pigeons  1959\n",
      "the clocks  1963\n",
      "crooked house  1949\n",
      "curtain poirots last case  1975\n",
      "dead mans folly  1956\n",
      "death comes at the end  1945\n",
      "death in the clouds also known as death in the air  1935\n",
      "death on the nile  1937\n",
      "destination unknown also known as so many steps to death  1954\n",
      "double sin and other stories  1961\n",
      "dumb witness also known as poirot loses a client  1937\n",
      "elephants can remember  1972\n",
      "endless night  1967\n",
      "evil under the sun  1941\n",
      "five little pigs also known as murder in retrospect  1943\n",
      "450 from paddington also known as what mrs mcgillicuty saw  1957\n",
      "the golden ball and other stories  1971\n",
      "halloween party  1969\n",
      "hercules poirots christmas also known as a holiday for murder  1938\n",
      "hickory dickory death  1955\n",
      "the hollow also known as murder after hours  1946\n",
      "the hound of death  1933\n",
      "the labours of hercules  1947\n",
      "the listerdale mystery morterblumen  1934\n",
      "lord edgware dies also known as thirteen at dinner  1933\n",
      "the man in the brown suit also known as mystery of the mill house  1924\n",
      "the mirror crackd from side to side also known as the mirror crackd  1962\n",
      "miss marples final cases  1979\n",
      "the mousetrap and other stories also known as 3 blind mice 1950\n",
      "the moving finger  1943\n",
      "mrs mcgintys dead  1952\n",
      "the murder in the vicarage  1930\n",
      "murder in mesopotamia  1936\n",
      "murder in the mews also known as dead mans mirror  1937\n",
      "a murder is announced  1950\n",
      "murder is easy easy to kill  1939\n",
      "the murder of roger ackroyd  1926\n",
      "murder on the links  1923\n",
      "murder on the orient express also known as murder on the calais coach  1934\n",
      "the mysterious affair at styles  1920\n",
      "the mysterious mr quin  1930\n",
      "the mystery of the blue train  1928\n",
      "nemesis  1971\n",
      "n or m  1941\n",
      "one two buckle my shoe also known as the patriotic murders  1940\n",
      "ordeal by innocence  1958\n",
      "the pale horse  1961\n",
      "parker pyne investigates also known as mr parker pyne detective  1934\n",
      "partners in crime  1929\n",
      "passenger to frankfurt  1970\n",
      "peril at end house  1932\n",
      "a pocket full of rye  1953\n",
      "poirot investigates  1924\n",
      "poirots early cases  1974\n",
      "postern of fate  1973\n",
      "problem at pollensa bay  19\n",
      "the regatta mystery  1939\n",
      "sad cypress  1940\n",
      "the secret adversary  1922\n",
      "the secret of chimneys  1925\n",
      "the seven dials mystery  1929\n",
      "the sittaford mystery also known as the murder at hazelmoor  1931\n",
      "sleeping murder  1976\n",
      "sparkling cyanide also known as remembered death  1945\n",
      "taken at the flood also known as there is a tide  1948\n",
      "they came to baghdad  1951\n",
      "they do it with mirrors also known as murder with mirrors  1952\n",
      "third girl  1966\n",
      "the thirteen problems also known as the tuesday club murders  1932\n",
      "threeact tragedy also known as murder in three acts  1935\n",
      "towards zero  1944\n",
      "the underdog and other stories  1951\n",
      "witness for the prosecution and other stories  1948\n",
      "why didnt they ask evans also known as the boomerang clue  1934\n"
     ]
    }
   ],
   "source": [
    "print(\"The new document is: \\n\",textdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization:\n",
    "* Tokenization is the process of breaking down a text paragraph into smaller parts such as words or sentence.\n",
    "* Token is a single entity that is the building block for a sentence or paragraph.\n",
    "* sentence tokenizer breaks text paragraph into sentences.\n",
    "* word tokenizer breaks text paragraph into words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ### Sentence tokenization using sent_tokenize() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence tokens are: \n",
      " ['The ABC Murders – 1936\\nThe Adventure of the Christmas Pudding – 1960\\nAfter the Funeral (also known as Funerals are Fatal) – 1953\\nAnd Then There Were None (also known as Ten Little Indians and Ten Little Niggers – 1939\\nAppointment with Death – 1938\\nAt Bertram’s Hotel – 1965\\nThe Big Four – 1927\\nThe Body in the Library – 1942\\nBy the Pricking of my Thumbs – 1968\\nCards on the Table – 1936\\nA Caribbean Mystery – 1964\\nCat Among the Pigeons – 1959\\nThe Clocks – 1963\\nCrooked House – 1949\\nCurtain: Poirot’s Last Case – 1975\\nDead Man’s Folly – 1956\\nDeath Comes At The End – 1945\\nDeath in the Clouds (also known as Death In The Air) – 1935\\nDeath on the Nile – 1937\\nDestination Unknown (also known as So Many Steps to Death) – 1954\\nDouble Sin and Other Stories – 1961\\nDumb Witness (also known as Poirot Loses a Client) – 1937\\nElephants Can Remember – 1972\\nEndless Night – 1967\\nEvil Under the Sun – 1941\\nFive Little Pigs (also known as Murder In Retrospect) – 1943\\n4.50 from Paddington (also known as What Mrs. McGillicuty Saw) – 1957\\nThe Golden Ball and Other Stories – 1971\\nHalloween Party – 1969\\nHercules Poirot’s Christmas (also known as A Holiday for Murder) – 1938\\nHickory Dickory Death – 1955\\nThe Hollow (also known as Murder After Hours) – 1946\\nThe Hound of Death – 1933\\nThe Labours of Hercules – 1947\\nThe Listerdale Mystery Morterblumen – 1934\\nLord Edgware Dies (also known as Thirteen At Dinner) – 1933\\nThe Man in the Brown Suit (also known as Mystery of the Mill House) – 1924\\nThe Mirror Crack’d from Side to Side (also known as The Mirror Crack’d) – 1962\\nMiss Marple’s Final Cases – 1979\\nThe Mousetrap and Other Stories (also known as 3 Blind Mice) 1950\\nThe Moving Finger – 1943\\nMrs. McGinty’s Dead – 1952\\nThe Murder in the Vicarage – 1930\\nMurder in Mesopotamia – 1936\\nMurder in the Mews (also known as Dead Man’s Mirror) – 1937\\nA Murder is Announced – 1950\\nMurder is Easy Easy to Kill – 1939\\nThe Murder of Roger Ackroyd – 1926\\nMurder on the Links – 1923\\nMurder on the Orient Express (also known as Murder on the Calais Coach) – 1934\\nThe Mysterious Affair at Styles – 1920\\nThe Mysterious Mr. Quin – 1930\\nThe Mystery of the Blue Train – 1928\\nNemesis – 1971\\nN or M?', '– 1941\\nOne, Two, Buckle My Shoe (also known as The Patriotic Murders) – 1940\\nOrdeal by Innocence – 1958\\nThe Pale Horse – 1961\\nParker Pyne Investigates (also known as Mr. Parker Pyne, Detective) – 1934\\nPartners in Crime – 1929\\nPassenger to Frankfurt – 1970\\nPeril at End House – 1932\\nA Pocket Full of Rye – 1953\\nPoirot Investigates – 1924\\nPoirot’s Early Cases – 1974\\nPostern of Fate – 1973\\nProblem at Pollensa Bay – 19??', 'The Regatta Mystery – 1939\\nSad Cypress – 1940\\nThe Secret Adversary – 1922\\nThe Secret of Chimneys – 1925\\nThe Seven Dials Mystery – 1929\\nThe Sittaford Mystery (also known as The Murder At Hazelmoor) – 1931\\nSleeping Murder – 1976\\nSparkling Cyanide (also known as Remembered Death) – 1945\\nTaken at the Flood (also known as There Is a Tide…) – 1948\\nThey Came to Baghdad – 1951\\nThey Do It With Mirrors (also known as Murder with Mirrors) – 1952\\nThird Girl – 1966\\nThe Thirteen Problems (also known as The Tuesday Club Murders – 1932\\nThree-Act Tragedy (also known as Murder In Three Acts) – 1935\\nTowards Zero – 1944\\nThe Underdog and Other Stories – 1951\\nWitness for the Prosecution and Other Stories – 1948\\nWhy Didn’t They Ask Evans (also known as The Boomerang Clue) – 1934']\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(textdata)\n",
    "print(\"The sentence tokens are: \\n\",sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize document into tokens/words using word_tokenize() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word tokens are: \n",
      " ['The', 'ABC', 'Murders', '–', '1936', 'The', 'Adventure', 'of', 'the', 'Christmas', 'Pudding', '–', '1960', 'After', 'the', 'Funeral', '(', 'also', 'known', 'as', 'Funerals', 'are', 'Fatal', ')', '–', '1953', 'And', 'Then', 'There', 'Were', 'None', '(', 'also', 'known', 'as', 'Ten', 'Little', 'Indians', 'and', 'Ten', 'Little', 'Niggers', '–', '1939', 'Appointment', 'with', 'Death', '–', '1938', 'At', 'Bertram', '’', 's', 'Hotel', '–', '1965', 'The', 'Big', 'Four', '–', '1927', 'The', 'Body', 'in', 'the', 'Library', '–', '1942', 'By', 'the', 'Pricking', 'of', 'my', 'Thumbs', '–', '1968', 'Cards', 'on', 'the', 'Table', '–', '1936', 'A', 'Caribbean', 'Mystery', '–', '1964', 'Cat', 'Among', 'the', 'Pigeons', '–', '1959', 'The', 'Clocks', '–', '1963', 'Crooked', 'House', '–', '1949', 'Curtain', ':', 'Poirot', '’', 's', 'Last', 'Case', '–', '1975', 'Dead', 'Man', '’', 's', 'Folly', '–', '1956', 'Death', 'Comes', 'At', 'The', 'End', '–', '1945', 'Death', 'in', 'the', 'Clouds', '(', 'also', 'known', 'as', 'Death', 'In', 'The', 'Air', ')', '–', '1935', 'Death', 'on', 'the', 'Nile', '–', '1937', 'Destination', 'Unknown', '(', 'also', 'known', 'as', 'So', 'Many', 'Steps', 'to', 'Death', ')', '–', '1954', 'Double', 'Sin', 'and', 'Other', 'Stories', '–', '1961', 'Dumb', 'Witness', '(', 'also', 'known', 'as', 'Poirot', 'Loses', 'a', 'Client', ')', '–', '1937', 'Elephants', 'Can', 'Remember', '–', '1972', 'Endless', 'Night', '–', '1967', 'Evil', 'Under', 'the', 'Sun', '–', '1941', 'Five', 'Little', 'Pigs', '(', 'also', 'known', 'as', 'Murder', 'In', 'Retrospect', ')', '–', '1943', '4.50', 'from', 'Paddington', '(', 'also', 'known', 'as', 'What', 'Mrs.', 'McGillicuty', 'Saw', ')', '–', '1957', 'The', 'Golden', 'Ball', 'and', 'Other', 'Stories', '–', '1971', 'Halloween', 'Party', '–', '1969', 'Hercules', 'Poirot', '’', 's', 'Christmas', '(', 'also', 'known', 'as', 'A', 'Holiday', 'for', 'Murder', ')', '–', '1938', 'Hickory', 'Dickory', 'Death', '–', '1955', 'The', 'Hollow', '(', 'also', 'known', 'as', 'Murder', 'After', 'Hours', ')', '–', '1946', 'The', 'Hound', 'of', 'Death', '–', '1933', 'The', 'Labours', 'of', 'Hercules', '–', '1947', 'The', 'Listerdale', 'Mystery', 'Morterblumen', '–', '1934', 'Lord', 'Edgware', 'Dies', '(', 'also', 'known', 'as', 'Thirteen', 'At', 'Dinner', ')', '–', '1933', 'The', 'Man', 'in', 'the', 'Brown', 'Suit', '(', 'also', 'known', 'as', 'Mystery', 'of', 'the', 'Mill', 'House', ')', '–', '1924', 'The', 'Mirror', 'Crack', '’', 'd', 'from', 'Side', 'to', 'Side', '(', 'also', 'known', 'as', 'The', 'Mirror', 'Crack', '’', 'd', ')', '–', '1962', 'Miss', 'Marple', '’', 's', 'Final', 'Cases', '–', '1979', 'The', 'Mousetrap', 'and', 'Other', 'Stories', '(', 'also', 'known', 'as', '3', 'Blind', 'Mice', ')', '1950', 'The', 'Moving', 'Finger', '–', '1943', 'Mrs.', 'McGinty', '’', 's', 'Dead', '–', '1952', 'The', 'Murder', 'in', 'the', 'Vicarage', '–', '1930', 'Murder', 'in', 'Mesopotamia', '–', '1936', 'Murder', 'in', 'the', 'Mews', '(', 'also', 'known', 'as', 'Dead', 'Man', '’', 's', 'Mirror', ')', '–', '1937', 'A', 'Murder', 'is', 'Announced', '–', '1950', 'Murder', 'is', 'Easy', 'Easy', 'to', 'Kill', '–', '1939', 'The', 'Murder', 'of', 'Roger', 'Ackroyd', '–', '1926', 'Murder', 'on', 'the', 'Links', '–', '1923', 'Murder', 'on', 'the', 'Orient', 'Express', '(', 'also', 'known', 'as', 'Murder', 'on', 'the', 'Calais', 'Coach', ')', '–', '1934', 'The', 'Mysterious', 'Affair', 'at', 'Styles', '–', '1920', 'The', 'Mysterious', 'Mr.', 'Quin', '–', '1930', 'The', 'Mystery', 'of', 'the', 'Blue', 'Train', '–', '1928', 'Nemesis', '–', '1971', 'N', 'or', 'M', '?', '–', '1941', 'One', ',', 'Two', ',', 'Buckle', 'My', 'Shoe', '(', 'also', 'known', 'as', 'The', 'Patriotic', 'Murders', ')', '–', '1940', 'Ordeal', 'by', 'Innocence', '–', '1958', 'The', 'Pale', 'Horse', '–', '1961', 'Parker', 'Pyne', 'Investigates', '(', 'also', 'known', 'as', 'Mr.', 'Parker', 'Pyne', ',', 'Detective', ')', '–', '1934', 'Partners', 'in', 'Crime', '–', '1929', 'Passenger', 'to', 'Frankfurt', '–', '1970', 'Peril', 'at', 'End', 'House', '–', '1932', 'A', 'Pocket', 'Full', 'of', 'Rye', '–', '1953', 'Poirot', 'Investigates', '–', '1924', 'Poirot', '’', 's', 'Early', 'Cases', '–', '1974', 'Postern', 'of', 'Fate', '–', '1973', 'Problem', 'at', 'Pollensa', 'Bay', '–', '19', '?', '?', 'The', 'Regatta', 'Mystery', '–', '1939', 'Sad', 'Cypress', '–', '1940', 'The', 'Secret', 'Adversary', '–', '1922', 'The', 'Secret', 'of', 'Chimneys', '–', '1925', 'The', 'Seven', 'Dials', 'Mystery', '–', '1929', 'The', 'Sittaford', 'Mystery', '(', 'also', 'known', 'as', 'The', 'Murder', 'At', 'Hazelmoor', ')', '–', '1931', 'Sleeping', 'Murder', '–', '1976', 'Sparkling', 'Cyanide', '(', 'also', 'known', 'as', 'Remembered', 'Death', ')', '–', '1945', 'Taken', 'at', 'the', 'Flood', '(', 'also', 'known', 'as', 'There', 'Is', 'a', 'Tide…', ')', '–', '1948', 'They', 'Came', 'to', 'Baghdad', '–', '1951', 'They', 'Do', 'It', 'With', 'Mirrors', '(', 'also', 'known', 'as', 'Murder', 'with', 'Mirrors', ')', '–', '1952', 'Third', 'Girl', '–', '1966', 'The', 'Thirteen', 'Problems', '(', 'also', 'known', 'as', 'The', 'Tuesday', 'Club', 'Murders', '–', '1932', 'Three-Act', 'Tragedy', '(', 'also', 'known', 'as', 'Murder', 'In', 'Three', 'Acts', ')', '–', '1935', 'Towards', 'Zero', '–', '1944', 'The', 'Underdog', 'and', 'Other', 'Stories', '–', '1951', 'Witness', 'for', 'the', 'Prosecution', 'and', 'Other', 'Stories', '–', '1948', 'Why', 'Didn', '’', 't', 'They', 'Ask', 'Evans', '(', 'also', 'known', 'as', 'The', 'Boomerang', 'Clue', ')', '–', '1934']\n"
     ]
    }
   ],
   "source": [
    "doc_tokens = nltk.word_tokenize(textdata)\n",
    "print(\"The word tokens are: \\n\",doc_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Stop Words:\n",
    "* stop words such as am,is,are,this,a,an,the etc.\n",
    "* These stop words are considered as noise in the text and hence should be removed.\n",
    "* Before doing analysis of text data,we should filter out the list of tokens from these stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading stop words from nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ### Storing all stop words of English from nltk corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the number of English stop words in nltk corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English stop words in corpus: 179\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of English stop words in corpus:\",len(eng_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the first 30 stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of first 30 stop words include: \n",
      " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of first 30 stop words include: \\n\",eng_stopwords[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the token (not in list of stop words) from list of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tokens = [token for token in doc_tokens if token not in eng_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining  the filtered tokens using join() function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdoc = ''.join(final_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining number of letters after removal of stop words in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of letters after removal of stop words: 2474\n",
      "First 298 letters from my new documnet are: \n",
      " TheABCMurders–1936TheAdventureChristmasPudding–1960AfterFuneral(alsoknownFuneralsFatal)–1953AndThenThereWereNone(alsoknownTenLittleIndiansTenLittleNiggers–1939AppointmentDeath–1938AtBertram’Hotel–1965TheBigFour–1927TheBodyLibrary–1942ByPrickingThumbs–1968CardsTable–1936ACaribbeanMystery–1964CatAmo\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of letters after removal of stop words:\",len(newdoc))\n",
    "print(\"First 298 letters from my new documnet are: \\n\",newdoc[0:298])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer and Bag of Words:\n",
    "* The vectorizer creates different columns based on bag of words.\n",
    "* TF-IDF (Term frequency-inverse document frequency) is a statistical measure used to evaluate how important a word is to a document in a collection of documents or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ### Creating bag of words using count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences are: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences are:\",len(sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer to remove unwanted elements from data like symbols,numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern='[a-zA-Z0-9]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)\n"
     ]
    }
   ],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer to display the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range=(1,1)) # token_pattern=token.tokenize\n",
    "text_counts= cv.fit_transform(sent_tokens).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating information of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of words: \n",
      " [[ 0  1  0  1  1  0  1  1  1  0  2  0  0  2  2  1  3  3  2  2  0  1  1  2\n",
      "   0  1  1  1  0  1  2  0  1  1  1  1  1  1  0  1  1  1  1  1  1  1  0  1\n",
      "   1  1  0  2  1  0  0  1  0  1  1  1  1  0  0  1  0  1  1  1  1  0  0  1\n",
      "   0  1  1  1  1  1  0  1  0  1  0  1  1  1  1  1  0  2  1  1  1  0  0  1\n",
      "   1  2  0  1  1  0  0  3  8  1  0  0  1  0  1  1  1  1  0  2  1  1  1  1\n",
      "   0  1  1  1  0  1  1  0  1  0  1  1  0  1  1  0  2  1  1  1  0  1  1  1\n",
      "   2  1  0  0  1 15  1  1  1  1  3  1  1  3  1  1  1  1  1  1  3  0  1  1\n",
      "   1  1  1  2 12  1  2  4  1  1  1  1  0  1  1  0  0  0  1  0  0  0  1  1\n",
      "   0  3  0  0  1  0  0  0  1  0  1  0  1  0  1  1  0  0  1  0  0  0  1  0\n",
      "   0  0  1  3  1  1  1  1  0  1  1  0  0  1  0  0  1  1  1  0]\n",
      " [ 1  0  0  0  1  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  1  1  0  0\n",
      "   0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  1  0  0  0  0  0  0\n",
      "   0  0  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  1  0\n",
      "   0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   1  0  1  2  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  1  0  0  0  0  0  0  1  0  0  1  2  1  0  1  1  1  0  0\n",
      "   1  2  1  1  0  1  0  0  0  2  0  0  0  0  0  0  1  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0  1  0  1  1  0  1  1  0  0  0  1  1  0  0  0\n",
      "   1  1  0  0  2  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "   0  0  0  0  0  0  0  0  1  0  0  0  0  1  1  0  1  0  0  0  0  1  1  0\n",
      "   0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  1  0  0  0  0  1  1  0\n",
      "   0  0  0  0  0  1  1  0  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0  0  0  0  0  0  1  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
      "   0  0  0  0  4  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  1  1  0  0  0  1  0  1  0  0  0  1  0  2  1  0  0  1\n",
      "   1  1  0  2  0  0  0  0  1  1  0  1  1  0  1  1  0  0  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Information of words: \\n\",text_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(text_counts,columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>1920</th>\n",
       "      <th>1922</th>\n",
       "      <th>1923</th>\n",
       "      <th>1924</th>\n",
       "      <th>1925</th>\n",
       "      <th>1926</th>\n",
       "      <th>1927</th>\n",
       "      <th>1928</th>\n",
       "      <th>1929</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbs</th>\n",
       "      <th>tide</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>train</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>underdog</th>\n",
       "      <th>unknown</th>\n",
       "      <th>vicarage</th>\n",
       "      <th>witness</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   19  1920  1922  1923  1924  1925  1926  1927  1928  1929  ...  thumbs  \\\n",
       "0   0     1     0     1     1     0     1     1     1     0  ...       1   \n",
       "1   1     0     0     0     1     0     0     0     0     1  ...       0   \n",
       "2   0     0     1     0     0     1     0     0     0     1  ...       0   \n",
       "\n",
       "   tide  tragedy  train  tuesday  underdog  unknown  vicarage  witness  zero  \n",
       "0     0        0      1        0         0        1         1        1     0  \n",
       "1     0        0      0        0         0        0         0        0     0  \n",
       "2     1        1      0        1         1        0         0        1     1  \n",
       "\n",
       "[3 rows x 236 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the shape of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataframe: (3, 236)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Dataframe:\",count_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the bag of words: \n",
      "    19  1920  1922  1923  1924  1925  1926  1927  1928  1929  ...  thumbs  \\\n",
      "0   0     1     0     1     1     0     1     1     1     0  ...       1   \n",
      "1   1     0     0     0     1     0     0     0     0     1  ...       0   \n",
      "2   0     0     1     0     0     1     0     0     0     1  ...       0   \n",
      "\n",
      "   tide  tragedy  train  tuesday  underdog  unknown  vicarage  witness  zero  \n",
      "0     0        0      1        0         0        1         1        1     0  \n",
      "1     0        0      0        0         0        0         0        0     0  \n",
      "2     1        1      0        1         1        0         0        1     1  \n",
      "\n",
      "[3 rows x 236 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the bag of words: \\n\",count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words using Tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying number of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences are: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences are:\",len(sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer to remove unwanted elements from data like symbols,numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming using Tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(lowercase=True,stop_words='english',ngram_range=(1,1))\n",
    "text_counts = tv.fit_transform(sent_tokens).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating information of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of words: \n",
      " [[0.         0.04689253 0.         0.04689253 0.03566298 0.\n",
      "  0.04689253 0.04689253 0.04689253 0.         0.09378505 0.\n",
      "  0.         0.09378505 0.05539096 0.03566298 0.14067758 0.14067758\n",
      "  0.09378505 0.07132595 0.         0.03566298 0.04689253 0.09378505\n",
      "  0.         0.03566298 0.04689253 0.04689253 0.         0.04689253\n",
      "  0.09378505 0.         0.03566298 0.03566298 0.04689253 0.04689253\n",
      "  0.04689253 0.04689253 0.         0.04689253 0.04689253 0.03566298\n",
      "  0.04689253 0.04689253 0.04689253 0.04689253 0.         0.04689253\n",
      "  0.04689253 0.04689253 0.         0.09378505 0.04689253 0.\n",
      "  0.         0.04689253 0.         0.04689253 0.04689253 0.04689253\n",
      "  0.04689253 0.         0.         0.04689253 0.         0.04689253\n",
      "  0.04689253 0.04689253 0.04689253 0.         0.         0.04689253\n",
      "  0.         0.04689253 0.04689253 0.04689253 0.04689253 0.04689253\n",
      "  0.         0.04689253 0.         0.04689253 0.         0.04689253\n",
      "  0.04689253 0.04689253 0.03566298 0.04689253 0.         0.09378505\n",
      "  0.04689253 0.04689253 0.04689253 0.         0.         0.04689253\n",
      "  0.04689253 0.09378505 0.         0.04689253 0.04689253 0.\n",
      "  0.         0.14067758 0.28530381 0.04689253 0.         0.\n",
      "  0.04689253 0.         0.04689253 0.04689253 0.04689253 0.04689253\n",
      "  0.         0.09378505 0.04689253 0.04689253 0.03566298 0.04689253\n",
      "  0.         0.04689253 0.04689253 0.04689253 0.         0.04689253\n",
      "  0.04689253 0.         0.04689253 0.         0.04689253 0.04689253\n",
      "  0.         0.04689253 0.04689253 0.         0.09378505 0.04689253\n",
      "  0.04689253 0.04689253 0.         0.04689253 0.04689253 0.04689253\n",
      "  0.07132595 0.04689253 0.         0.         0.04689253 0.41543223\n",
      "  0.04689253 0.04689253 0.04689253 0.04689253 0.14067758 0.04689253\n",
      "  0.04689253 0.14067758 0.04689253 0.04689253 0.04689253 0.04689253\n",
      "  0.04689253 0.04689253 0.14067758 0.         0.04689253 0.04689253\n",
      "  0.04689253 0.04689253 0.03566298 0.09378505 0.42795571 0.02769548\n",
      "  0.09378505 0.1426519  0.04689253 0.04689253 0.04689253 0.04689253\n",
      "  0.         0.04689253 0.04689253 0.         0.         0.\n",
      "  0.04689253 0.         0.         0.         0.04689253 0.04689253\n",
      "  0.         0.10698893 0.         0.         0.04689253 0.\n",
      "  0.         0.         0.04689253 0.         0.04689253 0.\n",
      "  0.04689253 0.         0.04689253 0.04689253 0.         0.\n",
      "  0.04689253 0.         0.         0.         0.04689253 0.\n",
      "  0.         0.         0.04689253 0.10698893 0.04689253 0.04689253\n",
      "  0.04689253 0.04689253 0.         0.03566298 0.04689253 0.\n",
      "  0.         0.04689253 0.         0.         0.04689253 0.04689253\n",
      "  0.03566298 0.        ]\n",
      " [0.14319514 0.         0.         0.         0.10890359 0.\n",
      "  0.         0.         0.         0.10890359 0.         0.\n",
      "  0.10890359 0.         0.08457335 0.         0.         0.\n",
      "  0.         0.         0.10890359 0.10890359 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.10890359 0.         0.\n",
      "  0.         0.         0.14319514 0.         0.         0.10890359\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14319514 0.         0.         0.14319514\n",
      "  0.14319514 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14319514 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14319514 0.         0.         0.\n",
      "  0.         0.         0.10890359 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14319514 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14319514 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14319514 0.         0.         0.         0.10890359 0.\n",
      "  0.         0.         0.         0.         0.14319514 0.\n",
      "  0.         0.         0.         0.14319514 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14319514 0.         0.         0.\n",
      "  0.10890359 0.         0.14319514 0.28639027 0.         0.16914671\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10890359 0.         0.         0.08457335\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14319514 0.         0.         0.14319514 0.28639027 0.14319514\n",
      "  0.         0.14319514 0.14319514 0.14319514 0.         0.\n",
      "  0.14319514 0.21780719 0.14319514 0.14319514 0.         0.14319514\n",
      "  0.         0.         0.         0.28639027 0.         0.\n",
      "  0.         0.         0.         0.         0.14319514 0.\n",
      "  0.         0.         0.         0.14319514 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.10241055 0.         0.         0.10241055\n",
      "  0.         0.         0.         0.07788587 0.         0.10241055\n",
      "  0.07788587 0.         0.06048532 0.07788587 0.         0.\n",
      "  0.         0.07788587 0.07788587 0.         0.         0.\n",
      "  0.10241055 0.07788587 0.         0.         0.20482111 0.\n",
      "  0.         0.20482111 0.07788587 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10241055 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10241055 0.         0.         0.\n",
      "  0.         0.10241055 0.10241055 0.         0.10241055 0.\n",
      "  0.         0.         0.         0.10241055 0.10241055 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10241055 0.         0.         0.         0.10241055 0.\n",
      "  0.         0.         0.         0.         0.10241055 0.\n",
      "  0.         0.         0.         0.10241055 0.10241055 0.\n",
      "  0.         0.         0.         0.         0.         0.10241055\n",
      "  0.10241055 0.         0.07788587 0.         0.         0.10241055\n",
      "  0.         0.10241055 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10241055 0.         0.         0.         0.         0.\n",
      "  0.         0.10241055 0.         0.         0.         0.\n",
      "  0.10241055 0.         0.         0.10241055 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.42339726\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20482111 0.         0.\n",
      "  0.         0.         0.         0.         0.31154347 0.06048532\n",
      "  0.         0.2336576  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10241055 0.10241055 0.         0.         0.         0.10241055\n",
      "  0.         0.10241055 0.         0.         0.         0.10241055\n",
      "  0.         0.20482111 0.10241055 0.         0.         0.10241055\n",
      "  0.10241055 0.10241055 0.         0.15577173 0.         0.\n",
      "  0.         0.         0.10241055 0.07788587 0.         0.10241055\n",
      "  0.10241055 0.         0.10241055 0.10241055 0.         0.\n",
      "  0.07788587 0.10241055]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Information of words: \\n\",text_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and displaying document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataframe: (3, 236)\n",
      "Displaying the bag of words: \n",
      "          19      1920      1922      1923      1924      1925      1926  \\\n",
      "0  0.000000  0.046893  0.000000  0.046893  0.035663  0.000000  0.046893   \n",
      "1  0.143195  0.000000  0.000000  0.000000  0.108904  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.102411  0.000000  0.000000  0.102411  0.000000   \n",
      "\n",
      "       1927      1928      1929  ...    thumbs      tide   tragedy     train  \\\n",
      "0  0.046893  0.046893  0.000000  ...  0.046893  0.000000  0.000000  0.046893   \n",
      "1  0.000000  0.000000  0.108904  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.077886  ...  0.000000  0.102411  0.102411  0.000000   \n",
      "\n",
      "    tuesday  underdog   unknown  vicarage   witness      zero  \n",
      "0  0.000000  0.000000  0.046893  0.046893  0.035663  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2  0.102411  0.102411  0.000000  0.000000  0.077886  0.102411  \n",
      "\n",
      "[3 rows x 236 columns]\n"
     ]
    }
   ],
   "source": [
    "count_df = pd.DataFrame(text_counts,columns=tv.get_feature_names_out())\n",
    "print(\"Shape of Dataframe:\",count_df.shape)\n",
    "print(\"Displaying the bag of words: \\n\",count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Parsing:\n",
    "  1. Shallow parsing (or Chunking) - It adds a bit more structure to a POS (Part of Speech) tagged sentence.The most common operation is grouping words into NP (Noun Phrases) , VP (Verb Phrases) and PP(Prepositional Phrases).\n",
    "  2. Constituency Parsing - It adds even more structure to the POS tagged sentence.\n",
    "  3. Dependency Parsing - It aids in finding the depedencies between the words and also their type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of Phrases:\n",
    "1. NP or Noun Phrase\n",
    "2. VP or Verb Phrase\n",
    "3. ADJP or Adjective Phrase\n",
    "4. ADVP or Adverb Phrase\n",
    "5. PP or Prepositional Phrase\n",
    "6. CC or Coordinating Conjunction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ### Dispalying the nature of the word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk_pos_tagged = nltk.pos_tag(final_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying token (words) and the POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of words and POS tag: \n",
      " [('The', 'DT'), ('ABC', 'NNP'), ('Murders', 'NNP'), ('–', 'NNP'), ('1936', 'CD'), ('The', 'DT'), ('Adventure', 'NNP'), ('Christmas', 'NNP'), ('Pudding', 'NNP'), ('–', 'NN'), ('1960', 'CD'), ('After', 'IN'), ('Funeral', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Funerals', 'NNP'), ('Fatal', 'NNP'), (')', ')'), ('–', 'NN'), ('1953', 'CD'), ('And', 'CC'), ('Then', 'RB'), ('There', 'EX'), ('Were', 'NNP'), ('None', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Ten', 'NNP'), ('Little', 'NNP'), ('Indians', 'NNP'), ('Ten', 'NNP'), ('Little', 'NNP'), ('Niggers', 'NNP'), ('–', 'NNP'), ('1939', 'CD'), ('Appointment', 'NNP'), ('Death', 'NNP'), ('–', 'NN'), ('1938', 'CD'), ('At', 'IN'), ('Bertram', 'NNP'), ('’', 'NNP'), ('Hotel', 'NNP'), ('–', 'NN'), ('1965', 'CD'), ('The', 'DT'), ('Big', 'NNP'), ('Four', 'CD'), ('–', 'NN'), ('1927', 'CD'), ('The', 'DT'), ('Body', 'NNP'), ('Library', 'NNP'), ('–', 'NN'), ('1942', 'CD'), ('By', 'IN'), ('Pricking', 'VBG'), ('Thumbs', 'NNP'), ('–', 'NN'), ('1968', 'CD'), ('Cards', 'NNP'), ('Table', 'NNP'), ('–', 'NN'), ('1936', 'CD'), ('A', 'NNP'), ('Caribbean', 'NNP'), ('Mystery', 'NNP'), ('–', 'NN'), ('1964', 'CD'), ('Cat', 'NNP'), ('Among', 'IN'), ('Pigeons', 'NNP'), ('–', 'NNP'), ('1959', 'CD'), ('The', 'DT'), ('Clocks', 'NNP'), ('–', 'NN'), ('1963', 'CD'), ('Crooked', 'NNP'), ('House', 'NNP'), ('–', 'NN'), ('1949', 'CD'), ('Curtain', 'NN'), (':', ':'), ('Poirot', 'NNP'), ('’', 'NNP'), ('Last', 'JJ'), ('Case', 'NNP'), ('–', 'NNP'), ('1975', 'CD'), ('Dead', 'NNP'), ('Man', 'NNP'), ('’', 'NNP'), ('Folly', 'NNP'), ('–', 'NNP'), ('1956', 'CD'), ('Death', 'NNP'), ('Comes', 'NNP'), ('At', 'IN'), ('The', 'DT'), ('End', 'NN'), ('–', 'NN'), ('1945', 'CD'), ('Death', 'NNP'), ('Clouds', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Death', 'NNP'), ('In', 'IN'), ('The', 'DT'), ('Air', 'NNP'), (')', ')'), ('–', 'NN'), ('1935', 'CD'), ('Death', 'NNP'), ('Nile', 'NNP'), ('–', 'NN'), ('1937', 'CD'), ('Destination', 'NNP'), ('Unknown', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('So', 'RB'), ('Many', 'JJ'), ('Steps', 'NNP'), ('Death', 'NNP'), (')', ')'), ('–', 'NN'), ('1954', 'CD'), ('Double', 'NNP'), ('Sin', 'NNP'), ('Other', 'JJ'), ('Stories', 'NNP'), ('–', 'NNP'), ('1961', 'CD'), ('Dumb', 'NNP'), ('Witness', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Poirot', 'NNP'), ('Loses', 'NNP'), ('Client', 'NNP'), (')', ')'), ('–', 'NN'), ('1937', 'CD'), ('Elephants', 'NNS'), ('Can', 'MD'), ('Remember', 'VB'), ('–', 'JJ'), ('1972', 'CD'), ('Endless', 'NNP'), ('Night', 'NNP'), ('–', 'NN'), ('1967', 'CD'), ('Evil', 'NNP'), ('Under', 'IN'), ('Sun', 'NNP'), ('–', 'NN'), ('1941', 'CD'), ('Five', 'NNP'), ('Little', 'NNP'), ('Pigs', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Murder', 'NNP'), ('In', 'IN'), ('Retrospect', 'NNP'), (')', ')'), ('–', 'NN'), ('1943', 'CD'), ('4.50', 'CD'), ('Paddington', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('What', 'WP'), ('Mrs.', 'NNP'), ('McGillicuty', 'NNP'), ('Saw', 'NNP'), (')', ')'), ('–', 'NN'), ('1957', 'CD'), ('The', 'DT'), ('Golden', 'NNP'), ('Ball', 'NNP'), ('Other', 'JJ'), ('Stories', 'NNP'), ('–', 'NNP'), ('1971', 'CD'), ('Halloween', 'NNP'), ('Party', 'NNP'), ('–', 'NN'), ('1969', 'CD'), ('Hercules', 'NNP'), ('Poirot', 'NNP'), ('’', 'NNP'), ('Christmas', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('A', 'NNP'), ('Holiday', 'NNP'), ('Murder', 'NNP'), (')', ')'), ('–', 'NN'), ('1938', 'CD'), ('Hickory', 'NNP'), ('Dickory', 'NNP'), ('Death', 'NNP'), ('–', 'NN'), ('1955', 'CD'), ('The', 'DT'), ('Hollow', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Murder', 'NN'), ('After', 'IN'), ('Hours', 'NNP'), (')', ')'), ('–', 'NN'), ('1946', 'CD'), ('The', 'DT'), ('Hound', 'NNP'), ('Death', 'NNP'), ('–', 'NN'), ('1933', 'CD'), ('The', 'DT'), ('Labours', 'NNP'), ('Hercules', 'NNP'), ('–', 'NNP'), ('1947', 'CD'), ('The', 'DT'), ('Listerdale', 'NNP'), ('Mystery', 'NNP'), ('Morterblumen', 'NNP'), ('–', 'NNP'), ('1934', 'CD'), ('Lord', 'NNP'), ('Edgware', 'NNP'), ('Dies', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Thirteen', 'NNP'), ('At', 'IN'), ('Dinner', 'NNP'), (')', ')'), ('–', 'NN'), ('1933', 'CD'), ('The', 'DT'), ('Man', 'NNP'), ('Brown', 'NNP'), ('Suit', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Mystery', 'NNP'), ('Mill', 'NNP'), ('House', 'NNP'), (')', ')'), ('–', 'NN'), ('1924', 'CD'), ('The', 'DT'), ('Mirror', 'NNP'), ('Crack', 'NNP'), ('’', 'NNP'), ('Side', 'NNP'), ('Side', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('The', 'DT'), ('Mirror', 'NNP'), ('Crack', 'NNP'), ('’', 'NNP'), (')', ')'), ('–', 'NN'), ('1962', 'CD'), ('Miss', 'NNP'), ('Marple', 'NNP'), ('’', 'NNP'), ('Final', 'NNP'), ('Cases', 'NNP'), ('–', 'NNP'), ('1979', 'CD'), ('The', 'DT'), ('Mousetrap', 'NNP'), ('Other', 'JJ'), ('Stories', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('3', 'CD'), ('Blind', 'NNP'), ('Mice', 'NNP'), (')', ')'), ('1950', 'CD'), ('The', 'DT'), ('Moving', 'NNP'), ('Finger', 'NNP'), ('–', 'NNP'), ('1943', 'CD'), ('Mrs.', 'NNP'), ('McGinty', 'NNP'), ('’', 'NNP'), ('Dead', 'NNP'), ('–', 'NN'), ('1952', 'CD'), ('The', 'DT'), ('Murder', 'NNP'), ('Vicarage', 'NNP'), ('–', 'JJ'), ('1930', 'CD'), ('Murder', 'NNP'), ('Mesopotamia', 'NNP'), ('–', 'NNP'), ('1936', 'CD'), ('Murder', 'NNP'), ('Mews', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Dead', 'NNP'), ('Man', 'NNP'), ('’', 'NNP'), ('Mirror', 'NNP'), (')', ')'), ('–', 'NN'), ('1937', 'CD'), ('A', 'NNP'), ('Murder', 'NNP'), ('Announced', 'NNP'), ('–', 'IN'), ('1950', 'CD'), ('Murder', 'NNP'), ('Easy', 'NNP'), ('Easy', 'NNP'), ('Kill', 'NNP'), ('–', 'NNP'), ('1939', 'CD'), ('The', 'DT'), ('Murder', 'NNP'), ('Roger', 'NNP'), ('Ackroyd', 'NNP'), ('–', 'NNP'), ('1926', 'CD'), ('Murder', 'NNP'), ('Links', 'NNP'), ('–', 'NNP'), ('1923', 'CD'), ('Murder', 'NNP'), ('Orient', 'NNP'), ('Express', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Murder', 'NNP'), ('Calais', 'NNP'), ('Coach', 'NNP'), (')', ')'), ('–', 'NN'), ('1934', 'CD'), ('The', 'DT'), ('Mysterious', 'NNP'), ('Affair', 'NNP'), ('Styles', 'NNP'), ('–', 'NNP'), ('1920', 'CD'), ('The', 'DT'), ('Mysterious', 'NNP'), ('Mr.', 'NNP'), ('Quin', 'NNP'), ('–', 'VBZ'), ('1930', 'CD'), ('The', 'DT'), ('Mystery', 'NNP'), ('Blue', 'NNP'), ('Train', 'NNP'), ('–', 'JJ'), ('1928', 'CD'), ('Nemesis', 'NNP'), ('–', 'NN'), ('1971', 'CD'), ('N', 'NNP'), ('M', 'NNP'), ('?', '.'), ('–', 'NN'), ('1941', 'CD'), ('One', 'CD'), (',', ','), ('Two', 'CD'), (',', ','), ('Buckle', 'NNP'), ('My', 'NNP'), ('Shoe', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('The', 'DT'), ('Patriotic', 'NNP'), ('Murders', 'NNP'), (')', ')'), ('–', 'NN'), ('1940', 'CD'), ('Ordeal', 'NNP'), ('Innocence', 'NNP'), ('–', 'NN'), ('1958', 'CD'), ('The', 'DT'), ('Pale', 'NNP'), ('Horse', 'NNP'), ('–', 'NN'), ('1961', 'CD'), ('Parker', 'NNP'), ('Pyne', 'NNP'), ('Investigates', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Mr.', 'NNP'), ('Parker', 'NNP'), ('Pyne', 'NNP'), (',', ','), ('Detective', 'NNP'), (')', ')'), ('–', 'NN'), ('1934', 'CD'), ('Partners', 'NNPS'), ('Crime', 'NNP'), ('–', 'NN'), ('1929', 'CD'), ('Passenger', 'NNP'), ('Frankfurt', 'NNP'), ('–', 'JJ'), ('1970', 'CD'), ('Peril', 'NNP'), ('End', 'NNP'), ('House', 'NNP'), ('–', 'NN'), ('1932', 'CD'), ('A', 'NNP'), ('Pocket', 'NNP'), ('Full', 'NNP'), ('Rye', 'NNP'), ('–', 'NNP'), ('1953', 'CD'), ('Poirot', 'NNP'), ('Investigates', 'NNP'), ('–', 'IN'), ('1924', 'CD'), ('Poirot', 'NNP'), ('’', 'VBD'), ('Early', 'JJ'), ('Cases', 'NNP'), ('–', 'NN'), ('1974', 'CD'), ('Postern', 'NNP'), ('Fate', 'NNP'), ('–', 'NN'), ('1973', 'CD'), ('Problem', 'NNP'), ('Pollensa', 'NNP'), ('Bay', 'NNP'), ('–', 'NNP'), ('19', 'CD'), ('?', '.'), ('?', '.'), ('The', 'DT'), ('Regatta', 'NNP'), ('Mystery', 'NNP'), ('–', 'NN'), ('1939', 'CD'), ('Sad', 'NNP'), ('Cypress', 'NNP'), ('–', 'NN'), ('1940', 'CD'), ('The', 'DT'), ('Secret', 'NNP'), ('Adversary', 'NNP'), ('–', 'NN'), ('1922', 'CD'), ('The', 'DT'), ('Secret', 'NNP'), ('Chimneys', 'NNP'), ('–', 'NNP'), ('1925', 'CD'), ('The', 'DT'), ('Seven', 'NNP'), ('Dials', 'NNP'), ('Mystery', 'NNP'), ('–', 'NN'), ('1929', 'CD'), ('The', 'DT'), ('Sittaford', 'NNP'), ('Mystery', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('The', 'DT'), ('Murder', 'NN'), ('At', 'IN'), ('Hazelmoor', 'NNP'), (')', ')'), ('–', 'NN'), ('1931', 'CD'), ('Sleeping', 'VBG'), ('Murder', 'NNP'), ('–', 'NN'), ('1976', 'CD'), ('Sparkling', 'NNP'), ('Cyanide', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Remembered', 'NNP'), ('Death', 'NNP'), (')', ')'), ('–', 'NN'), ('1945', 'CD'), ('Taken', 'NNP'), ('Flood', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('There', 'EX'), ('Is', 'NNP'), ('Tide…', 'NNP'), (')', ')'), ('–', 'VBP'), ('1948', 'CD'), ('They', 'PRP'), ('Came', 'NNP'), ('Baghdad', 'NNP'), ('–', 'NN'), ('1951', 'CD'), ('They', 'PRP'), ('Do', 'VBP'), ('It', 'PRP'), ('With', 'IN'), ('Mirrors', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Murder', 'NNP'), ('Mirrors', 'NNPS'), (')', ')'), ('–', 'NN'), ('1952', 'CD'), ('Third', 'NNP'), ('Girl', 'NNP'), ('–', 'NNP'), ('1966', 'CD'), ('The', 'DT'), ('Thirteen', 'NNP'), ('Problems', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('The', 'DT'), ('Tuesday', 'NNP'), ('Club', 'NNP'), ('Murders', 'NNP'), ('–', 'JJ'), ('1932', 'CD'), ('Three-Act', 'JJ'), ('Tragedy', 'NNP'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('Murder', 'NN'), ('In', 'IN'), ('Three', 'NNP'), ('Acts', 'NNP'), (')', ')'), ('–', 'NN'), ('1935', 'CD'), ('Towards', 'NNP'), ('Zero', 'NNP'), ('–', 'NN'), ('1944', 'CD'), ('The', 'DT'), ('Underdog', 'NNP'), ('Other', 'JJ'), ('Stories', 'NNP'), ('–', 'NNP'), ('1951', 'CD'), ('Witness', 'NNP'), ('Prosecution', 'NNP'), ('Other', 'JJ'), ('Stories', 'NNP'), ('–', 'NNP'), ('1948', 'CD'), ('Why', 'WRB'), ('Didn', 'NNP'), ('’', 'NN'), ('They', 'PRP'), ('Ask', 'VBP'), ('Evans', 'NNS'), ('(', '('), ('also', 'RB'), ('known', 'VBN'), ('The', 'DT'), ('Boomerang', 'NNP'), ('Clue', 'NNP'), (')', ')'), ('–', 'NN'), ('1934', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "print('Information of words and POS tag: \\n',nltk_pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization \n",
    "- Another type of noise in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stemming - is the process of gathering words of similar origin into one word. It helps us to increase accuracy in our minded text by removing suffixes and reducing words to their basic forms.\n",
    "   - Example - Detection,detected,detecting are reduced to a common word \"Detect\". \n",
    "2. Lemmatization - more sophisticated than Stemming and it also reduces words to their base word. \n",
    "   - Example - better has \"good\" as its lemma.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the file with the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hackthebox/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating objects for stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of words having same base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming word Program : program\n",
      "Lemmatizing word Program : Program\n",
      "Stemming word Programs : program\n",
      "Lemmatizing word Programs : Programs\n",
      "Stemming word Programming : program\n",
      "Lemmatizing word Programming : Programming\n",
      "Stemming word Programmer : programm\n",
      "Lemmatizing word Programmer : Programmer\n",
      "Stemming word Programmers : programm\n",
      "Lemmatizing word Programmers : Programmers\n"
     ]
    }
   ],
   "source": [
    "my_words = [\"Program\",\"Programs\",\"Programming\",\"Programmer\",\"Programmers\"]\n",
    "for word in my_words:\n",
    "    print(\"Stemming word\",word,\":\",ps.stem(word))\n",
    "    print(\"Lemmatizing word\",word,\":\",lem.lemmatize(word,'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Stemming and Lemmatization on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries, Creating objects and empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "lemlist = []\n",
    "pslist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of words having same base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in final_tokens:\n",
    "    lemlist.append(lem.lemmatize(word,'v'))\n",
    "    pslist.append(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the result after lemmatization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization: \n",
      " ['The', 'ABC', 'Murders', '–', '1936', 'The', 'Adventure', 'Christmas', 'Pudding', '–', '1960', 'After', 'Funeral', '(', 'also', 'know', 'Funerals', 'Fatal', ')', '–']\n",
      "After Stemming: \n",
      " ['the', 'abc', 'murder', '–', '1936', 'the', 'adventur', 'christma', 'pud', '–', '1960', 'after', 'funer', '(', 'also', 'known', 'funer', 'fatal', ')', '–']\n"
     ]
    }
   ],
   "source": [
    "print(\"After Lemmatization: \\n\",lemlist[0:20])\n",
    "print(\"After Stemming: \\n\",pslist[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distribution \n",
    "- frequency of the words that are occuring in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ### Displaying the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution: \n",
      " <FreqDist with 284 samples and 614 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'–': 84, 'The': 34, '(': 24, 'also': 24, 'know': 24, ')': 22, 'Murder': 16, '’': 11, 'Death': 9, 'Mystery': 7, ...})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = FreqDist(lemlist)\n",
    "print(\"Frequency Distribution: \\n\",dist)\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('–', 84), ('The', 34)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common words:\",dist.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the word with maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word with maximum frequency: –\n"
     ]
    }
   ],
   "source": [
    "print(\"Word with maximum frequency:\",dist.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the frequency of the word \"The\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of THE word: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequency of THE word:\",dist['The'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itens of dictionary: \n",
      " dict_items([('The', 34), ('ABC', 1), ('Murders', 3), ('–', 84), ('1936', 3), ('Adventure', 1), ('Christmas', 2), ('Pudding', 1), ('1960', 1), ('After', 2), ('Funeral', 1), ('(', 24), ('also', 24), ('know', 24), ('Funerals', 1), ('Fatal', 1), (')', 22), ('1953', 2), ('And', 1), ('Then', 1), ('There', 2), ('Were', 1), ('None', 1), ('Ten', 2), ('Little', 3), ('Indians', 1), ('Niggers', 1), ('1939', 3), ('Appointment', 1), ('Death', 9), ('1938', 2), ('At', 4), ('Bertram', 1), ('’', 11), ('Hotel', 1), ('1965', 1), ('Big', 1), ('Four', 1), ('1927', 1), ('Body', 1), ('Library', 1), ('1942', 1), ('By', 1), ('Pricking', 1), ('Thumbs', 1), ('1968', 1), ('Cards', 1), ('Table', 1), ('A', 4), ('Caribbean', 1), ('Mystery', 7), ('1964', 1), ('Cat', 1), ('Among', 1), ('Pigeons', 1), ('1959', 1), ('Clocks', 1), ('1963', 1), ('Crooked', 1), ('House', 3), ('1949', 1), ('Curtain', 1), (':', 1), ('Poirot', 5), ('Last', 1), ('Case', 1), ('1975', 1), ('Dead', 3), ('Man', 3), ('Folly', 1), ('1956', 1), ('Comes', 1), ('End', 2), ('1945', 2), ('Clouds', 1), ('In', 3), ('Air', 1), ('1935', 2), ('Nile', 1), ('1937', 3), ('Destination', 1), ('Unknown', 1), ('So', 1), ('Many', 1), ('Steps', 1), ('1954', 1), ('Double', 1), ('Sin', 1), ('Other', 5), ('Stories', 5), ('1961', 2), ('Dumb', 1), ('Witness', 2), ('Loses', 1), ('Client', 1), ('Elephants', 1), ('Can', 1), ('Remember', 1), ('1972', 1), ('Endless', 1), ('Night', 1), ('1967', 1), ('Evil', 1), ('Under', 1), ('Sun', 1), ('1941', 2), ('Five', 1), ('Pigs', 1), ('Murder', 16), ('Retrospect', 1), ('1943', 2), ('4.50', 1), ('Paddington', 1), ('What', 1), ('Mrs.', 2), ('McGillicuty', 1), ('Saw', 1), ('1957', 1), ('Golden', 1), ('Ball', 1), ('1971', 2), ('Halloween', 1), ('Party', 1), ('1969', 1), ('Hercules', 2), ('Holiday', 1), ('Hickory', 1), ('Dickory', 1), ('1955', 1), ('Hollow', 1), ('Hours', 1), ('1946', 1), ('Hound', 1), ('1933', 2), ('Labours', 1), ('1947', 1), ('Listerdale', 1), ('Morterblumen', 1), ('1934', 4), ('Lord', 1), ('Edgware', 1), ('Dies', 1), ('Thirteen', 2), ('Dinner', 1), ('Brown', 1), ('Suit', 1), ('Mill', 1), ('1924', 2), ('Mirror', 3), ('Crack', 2), ('Side', 2), ('1962', 1), ('Miss', 1), ('Marple', 1), ('Final', 1), ('Cases', 2), ('1979', 1), ('Mousetrap', 1), ('3', 1), ('Blind', 1), ('Mice', 1), ('1950', 2), ('Moving', 1), ('Finger', 1), ('McGinty', 1), ('1952', 2), ('Vicarage', 1), ('1930', 2), ('Mesopotamia', 1), ('Mews', 1), ('Announced', 1), ('Easy', 2), ('Kill', 1), ('Roger', 1), ('Ackroyd', 1), ('1926', 1), ('Links', 1), ('1923', 1), ('Orient', 1), ('Express', 1), ('Calais', 1), ('Coach', 1), ('Mysterious', 2), ('Affair', 1), ('Styles', 1), ('1920', 1), ('Mr.', 2), ('Quin', 1), ('Blue', 1), ('Train', 1), ('1928', 1), ('Nemesis', 1), ('N', 1), ('M', 1), ('?', 3), ('One', 1), (',', 3), ('Two', 1), ('Buckle', 1), ('My', 1), ('Shoe', 1), ('Patriotic', 1), ('1940', 2), ('Ordeal', 1), ('Innocence', 1), ('1958', 1), ('Pale', 1), ('Horse', 1), ('Parker', 2), ('Pyne', 2), ('Investigates', 2), ('Detective', 1), ('Partners', 1), ('Crime', 1), ('1929', 2), ('Passenger', 1), ('Frankfurt', 1), ('1970', 1), ('Peril', 1), ('1932', 2), ('Pocket', 1), ('Full', 1), ('Rye', 1), ('Early', 1), ('1974', 1), ('Postern', 1), ('Fate', 1), ('1973', 1), ('Problem', 1), ('Pollensa', 1), ('Bay', 1), ('19', 1), ('Regatta', 1), ('Sad', 1), ('Cypress', 1), ('Secret', 2), ('Adversary', 1), ('1922', 1), ('Chimneys', 1), ('1925', 1), ('Seven', 1), ('Dials', 1), ('Sittaford', 1), ('Hazelmoor', 1), ('1931', 1), ('Sleeping', 1), ('1976', 1), ('Sparkling', 1), ('Cyanide', 1), ('Remembered', 1), ('Taken', 1), ('Flood', 1), ('Is', 1), ('Tide…', 1), ('1948', 2), ('They', 3), ('Came', 1), ('Baghdad', 1), ('1951', 2), ('Do', 1), ('It', 1), ('With', 1), ('Mirrors', 2), ('Third', 1), ('Girl', 1), ('1966', 1), ('Problems', 1), ('Tuesday', 1), ('Club', 1), ('Three-Act', 1), ('Tragedy', 1), ('Three', 1), ('Acts', 1), ('Towards', 1), ('Zero', 1), ('1944', 1), ('Underdog', 1), ('Prosecution', 1), ('Why', 1), ('Didn', 1), ('Ask', 1), ('Evans', 1), ('Boomerang', 1), ('Clue', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(\"Itens of dictionary: \\n\",dist.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of bigrams: \n",
      " [('The', 'ABC'), ('ABC', 'Murders'), ('Murders', '–'), ('–', '1936'), ('1936', 'The'), ('The', 'Adventure'), ('Adventure', 'Christmas'), ('Christmas', 'Pudding'), ('Pudding', '–'), ('–', '1960'), ('1960', 'After'), ('After', 'Funeral'), ('Funeral', '('), ('(', 'also'), ('also', 'know'), ('know', 'Funerals'), ('Funerals', 'Fatal'), ('Fatal', ')'), (')', '–'), ('–', '1953'), ('1953', 'And'), ('And', 'Then'), ('Then', 'There'), ('There', 'Were'), ('Were', 'None'), ('None', '('), ('(', 'also'), ('also', 'know'), ('know', 'Ten'), ('Ten', 'Little'), ('Little', 'Indians'), ('Indians', 'Ten'), ('Ten', 'Little'), ('Little', 'Niggers'), ('Niggers', '–'), ('–', '1939'), ('1939', 'Appointment'), ('Appointment', 'Death'), ('Death', '–'), ('–', '1938'), ('1938', 'At'), ('At', 'Bertram'), ('Bertram', '’'), ('’', 'Hotel'), ('Hotel', '–'), ('–', '1965'), ('1965', 'The'), ('The', 'Big'), ('Big', 'Four'), ('Four', '–'), ('–', '1927'), ('1927', 'The'), ('The', 'Body'), ('Body', 'Library'), ('Library', '–'), ('–', '1942'), ('1942', 'By'), ('By', 'Pricking'), ('Pricking', 'Thumbs'), ('Thumbs', '–'), ('–', '1968'), ('1968', 'Cards'), ('Cards', 'Table'), ('Table', '–'), ('–', '1936'), ('1936', 'A'), ('A', 'Caribbean'), ('Caribbean', 'Mystery'), ('Mystery', '–'), ('–', '1964'), ('1964', 'Cat'), ('Cat', 'Among'), ('Among', 'Pigeons'), ('Pigeons', '–'), ('–', '1959'), ('1959', 'The'), ('The', 'Clocks'), ('Clocks', '–'), ('–', '1963'), ('1963', 'Crooked'), ('Crooked', 'House'), ('House', '–'), ('–', '1949'), ('1949', 'Curtain'), ('Curtain', ':'), (':', 'Poirot'), ('Poirot', '’'), ('’', 'Last'), ('Last', 'Case'), ('Case', '–'), ('–', '1975'), ('1975', 'Dead'), ('Dead', 'Man'), ('Man', '’'), ('’', 'Folly'), ('Folly', '–'), ('–', '1956'), ('1956', 'Death'), ('Death', 'Comes'), ('Comes', 'At'), ('At', 'The'), ('The', 'End'), ('End', '–'), ('–', '1945'), ('1945', 'Death'), ('Death', 'Clouds'), ('Clouds', '('), ('(', 'also'), ('also', 'know'), ('know', 'Death'), ('Death', 'In'), ('In', 'The'), ('The', 'Air'), ('Air', ')'), (')', '–'), ('–', '1935'), ('1935', 'Death'), ('Death', 'Nile'), ('Nile', '–'), ('–', '1937'), ('1937', 'Destination'), ('Destination', 'Unknown'), ('Unknown', '('), ('(', 'also'), ('also', 'know'), ('know', 'So'), ('So', 'Many'), ('Many', 'Steps'), ('Steps', 'Death'), ('Death', ')'), (')', '–'), ('–', '1954'), ('1954', 'Double'), ('Double', 'Sin'), ('Sin', 'Other'), ('Other', 'Stories'), ('Stories', '–'), ('–', '1961'), ('1961', 'Dumb'), ('Dumb', 'Witness'), ('Witness', '('), ('(', 'also'), ('also', 'know'), ('know', 'Poirot'), ('Poirot', 'Loses'), ('Loses', 'Client'), ('Client', ')'), (')', '–'), ('–', '1937'), ('1937', 'Elephants'), ('Elephants', 'Can'), ('Can', 'Remember'), ('Remember', '–'), ('–', '1972'), ('1972', 'Endless'), ('Endless', 'Night'), ('Night', '–'), ('–', '1967'), ('1967', 'Evil'), ('Evil', 'Under'), ('Under', 'Sun'), ('Sun', '–'), ('–', '1941'), ('1941', 'Five'), ('Five', 'Little'), ('Little', 'Pigs'), ('Pigs', '('), ('(', 'also'), ('also', 'know'), ('know', 'Murder'), ('Murder', 'In'), ('In', 'Retrospect'), ('Retrospect', ')'), (')', '–'), ('–', '1943'), ('1943', '4.50'), ('4.50', 'Paddington'), ('Paddington', '('), ('(', 'also'), ('also', 'know'), ('know', 'What'), ('What', 'Mrs.'), ('Mrs.', 'McGillicuty'), ('McGillicuty', 'Saw'), ('Saw', ')'), (')', '–'), ('–', '1957'), ('1957', 'The'), ('The', 'Golden'), ('Golden', 'Ball'), ('Ball', 'Other'), ('Other', 'Stories'), ('Stories', '–'), ('–', '1971'), ('1971', 'Halloween'), ('Halloween', 'Party'), ('Party', '–'), ('–', '1969'), ('1969', 'Hercules'), ('Hercules', 'Poirot'), ('Poirot', '’'), ('’', 'Christmas'), ('Christmas', '('), ('(', 'also'), ('also', 'know'), ('know', 'A'), ('A', 'Holiday'), ('Holiday', 'Murder'), ('Murder', ')'), (')', '–'), ('–', '1938'), ('1938', 'Hickory'), ('Hickory', 'Dickory'), ('Dickory', 'Death'), ('Death', '–'), ('–', '1955'), ('1955', 'The'), ('The', 'Hollow'), ('Hollow', '('), ('(', 'also'), ('also', 'know'), ('know', 'Murder'), ('Murder', 'After'), ('After', 'Hours'), ('Hours', ')'), (')', '–'), ('–', '1946'), ('1946', 'The'), ('The', 'Hound'), ('Hound', 'Death'), ('Death', '–'), ('–', '1933'), ('1933', 'The'), ('The', 'Labours'), ('Labours', 'Hercules'), ('Hercules', '–'), ('–', '1947'), ('1947', 'The'), ('The', 'Listerdale'), ('Listerdale', 'Mystery'), ('Mystery', 'Morterblumen'), ('Morterblumen', '–'), ('–', '1934'), ('1934', 'Lord'), ('Lord', 'Edgware'), ('Edgware', 'Dies'), ('Dies', '('), ('(', 'also'), ('also', 'know'), ('know', 'Thirteen'), ('Thirteen', 'At'), ('At', 'Dinner'), ('Dinner', ')'), (')', '–'), ('–', '1933'), ('1933', 'The'), ('The', 'Man'), ('Man', 'Brown'), ('Brown', 'Suit'), ('Suit', '('), ('(', 'also'), ('also', 'know'), ('know', 'Mystery'), ('Mystery', 'Mill'), ('Mill', 'House'), ('House', ')'), (')', '–'), ('–', '1924'), ('1924', 'The'), ('The', 'Mirror'), ('Mirror', 'Crack'), ('Crack', '’'), ('’', 'Side'), ('Side', 'Side'), ('Side', '('), ('(', 'also'), ('also', 'know'), ('know', 'The'), ('The', 'Mirror'), ('Mirror', 'Crack'), ('Crack', '’'), ('’', ')'), (')', '–'), ('–', '1962'), ('1962', 'Miss'), ('Miss', 'Marple'), ('Marple', '’'), ('’', 'Final'), ('Final', 'Cases'), ('Cases', '–'), ('–', '1979'), ('1979', 'The'), ('The', 'Mousetrap'), ('Mousetrap', 'Other'), ('Other', 'Stories'), ('Stories', '('), ('(', 'also'), ('also', 'know'), ('know', '3'), ('3', 'Blind'), ('Blind', 'Mice'), ('Mice', ')'), (')', '1950'), ('1950', 'The'), ('The', 'Moving'), ('Moving', 'Finger'), ('Finger', '–'), ('–', '1943'), ('1943', 'Mrs.'), ('Mrs.', 'McGinty'), ('McGinty', '’'), ('’', 'Dead'), ('Dead', '–'), ('–', '1952'), ('1952', 'The'), ('The', 'Murder'), ('Murder', 'Vicarage'), ('Vicarage', '–'), ('–', '1930'), ('1930', 'Murder'), ('Murder', 'Mesopotamia'), ('Mesopotamia', '–'), ('–', '1936'), ('1936', 'Murder'), ('Murder', 'Mews'), ('Mews', '('), ('(', 'also'), ('also', 'know'), ('know', 'Dead'), ('Dead', 'Man'), ('Man', '’'), ('’', 'Mirror'), ('Mirror', ')'), (')', '–'), ('–', '1937'), ('1937', 'A'), ('A', 'Murder'), ('Murder', 'Announced'), ('Announced', '–'), ('–', '1950'), ('1950', 'Murder'), ('Murder', 'Easy'), ('Easy', 'Easy'), ('Easy', 'Kill'), ('Kill', '–'), ('–', '1939'), ('1939', 'The'), ('The', 'Murder'), ('Murder', 'Roger'), ('Roger', 'Ackroyd'), ('Ackroyd', '–'), ('–', '1926'), ('1926', 'Murder'), ('Murder', 'Links'), ('Links', '–'), ('–', '1923'), ('1923', 'Murder'), ('Murder', 'Orient'), ('Orient', 'Express'), ('Express', '('), ('(', 'also'), ('also', 'know'), ('know', 'Murder'), ('Murder', 'Calais'), ('Calais', 'Coach'), ('Coach', ')'), (')', '–'), ('–', '1934'), ('1934', 'The'), ('The', 'Mysterious'), ('Mysterious', 'Affair'), ('Affair', 'Styles'), ('Styles', '–'), ('–', '1920'), ('1920', 'The'), ('The', 'Mysterious'), ('Mysterious', 'Mr.'), ('Mr.', 'Quin'), ('Quin', '–'), ('–', '1930'), ('1930', 'The'), ('The', 'Mystery'), ('Mystery', 'Blue'), ('Blue', 'Train'), ('Train', '–'), ('–', '1928'), ('1928', 'Nemesis'), ('Nemesis', '–'), ('–', '1971'), ('1971', 'N'), ('N', 'M'), ('M', '?'), ('?', '–'), ('–', '1941'), ('1941', 'One'), ('One', ','), (',', 'Two'), ('Two', ','), (',', 'Buckle'), ('Buckle', 'My'), ('My', 'Shoe'), ('Shoe', '('), ('(', 'also'), ('also', 'know'), ('know', 'The'), ('The', 'Patriotic'), ('Patriotic', 'Murders'), ('Murders', ')'), (')', '–'), ('–', '1940'), ('1940', 'Ordeal'), ('Ordeal', 'Innocence'), ('Innocence', '–'), ('–', '1958'), ('1958', 'The'), ('The', 'Pale'), ('Pale', 'Horse'), ('Horse', '–'), ('–', '1961'), ('1961', 'Parker'), ('Parker', 'Pyne'), ('Pyne', 'Investigates'), ('Investigates', '('), ('(', 'also'), ('also', 'know'), ('know', 'Mr.'), ('Mr.', 'Parker'), ('Parker', 'Pyne'), ('Pyne', ','), (',', 'Detective'), ('Detective', ')'), (')', '–'), ('–', '1934'), ('1934', 'Partners'), ('Partners', 'Crime'), ('Crime', '–'), ('–', '1929'), ('1929', 'Passenger'), ('Passenger', 'Frankfurt'), ('Frankfurt', '–'), ('–', '1970'), ('1970', 'Peril'), ('Peril', 'End'), ('End', 'House'), ('House', '–'), ('–', '1932'), ('1932', 'A'), ('A', 'Pocket'), ('Pocket', 'Full'), ('Full', 'Rye'), ('Rye', '–'), ('–', '1953'), ('1953', 'Poirot'), ('Poirot', 'Investigates'), ('Investigates', '–'), ('–', '1924'), ('1924', 'Poirot'), ('Poirot', '’'), ('’', 'Early'), ('Early', 'Cases'), ('Cases', '–'), ('–', '1974'), ('1974', 'Postern'), ('Postern', 'Fate'), ('Fate', '–'), ('–', '1973'), ('1973', 'Problem'), ('Problem', 'Pollensa'), ('Pollensa', 'Bay'), ('Bay', '–'), ('–', '19'), ('19', '?'), ('?', '?'), ('?', 'The'), ('The', 'Regatta'), ('Regatta', 'Mystery'), ('Mystery', '–'), ('–', '1939'), ('1939', 'Sad'), ('Sad', 'Cypress'), ('Cypress', '–'), ('–', '1940'), ('1940', 'The'), ('The', 'Secret'), ('Secret', 'Adversary'), ('Adversary', '–'), ('–', '1922'), ('1922', 'The'), ('The', 'Secret'), ('Secret', 'Chimneys'), ('Chimneys', '–'), ('–', '1925'), ('1925', 'The'), ('The', 'Seven'), ('Seven', 'Dials'), ('Dials', 'Mystery'), ('Mystery', '–'), ('–', '1929'), ('1929', 'The'), ('The', 'Sittaford'), ('Sittaford', 'Mystery'), ('Mystery', '('), ('(', 'also'), ('also', 'know'), ('know', 'The'), ('The', 'Murder'), ('Murder', 'At'), ('At', 'Hazelmoor'), ('Hazelmoor', ')'), (')', '–'), ('–', '1931'), ('1931', 'Sleeping'), ('Sleeping', 'Murder'), ('Murder', '–'), ('–', '1976'), ('1976', 'Sparkling'), ('Sparkling', 'Cyanide'), ('Cyanide', '('), ('(', 'also'), ('also', 'know'), ('know', 'Remembered'), ('Remembered', 'Death'), ('Death', ')'), (')', '–'), ('–', '1945'), ('1945', 'Taken'), ('Taken', 'Flood'), ('Flood', '('), ('(', 'also'), ('also', 'know'), ('know', 'There'), ('There', 'Is'), ('Is', 'Tide…'), ('Tide…', ')'), (')', '–'), ('–', '1948'), ('1948', 'They'), ('They', 'Came'), ('Came', 'Baghdad'), ('Baghdad', '–'), ('–', '1951'), ('1951', 'They'), ('They', 'Do'), ('Do', 'It'), ('It', 'With'), ('With', 'Mirrors'), ('Mirrors', '('), ('(', 'also'), ('also', 'know'), ('know', 'Murder'), ('Murder', 'Mirrors'), ('Mirrors', ')'), (')', '–'), ('–', '1952'), ('1952', 'Third'), ('Third', 'Girl'), ('Girl', '–'), ('–', '1966'), ('1966', 'The'), ('The', 'Thirteen'), ('Thirteen', 'Problems'), ('Problems', '('), ('(', 'also'), ('also', 'know'), ('know', 'The'), ('The', 'Tuesday'), ('Tuesday', 'Club'), ('Club', 'Murders'), ('Murders', '–'), ('–', '1932'), ('1932', 'Three-Act'), ('Three-Act', 'Tragedy'), ('Tragedy', '('), ('(', 'also'), ('also', 'know'), ('know', 'Murder'), ('Murder', 'In'), ('In', 'Three'), ('Three', 'Acts'), ('Acts', ')'), (')', '–'), ('–', '1935'), ('1935', 'Towards'), ('Towards', 'Zero'), ('Zero', '–'), ('–', '1944'), ('1944', 'The'), ('The', 'Underdog'), ('Underdog', 'Other'), ('Other', 'Stories'), ('Stories', '–'), ('–', '1951'), ('1951', 'Witness'), ('Witness', 'Prosecution'), ('Prosecution', 'Other'), ('Other', 'Stories'), ('Stories', '–'), ('–', '1948'), ('1948', 'Why'), ('Why', 'Didn'), ('Didn', '’'), ('’', 'They'), ('They', 'Ask'), ('Ask', 'Evans'), ('Evans', '('), ('(', 'also'), ('also', 'know'), ('know', 'The'), ('The', 'Boomerang'), ('Boomerang', 'Clue'), ('Clue', ')'), (')', '–'), ('–', '1934')]\n"
     ]
    }
   ],
   "source": [
    "print(\"List of bigrams: \\n\",list(ngrams(lemlist,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution for bigrams using ngrams function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of bigrams: \n",
      " <FreqDist with 483 samples and 613 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({('(', 'also'): 24, ('also', 'know'): 24, (')', '–'): 21, ('Other', 'Stories'): 5, ('know', 'Murder'): 5, ('know', 'The'): 5, ('Stories', '–'): 4, ('–', '1934'): 4, ('–', '1936'): 3, ('–', '1939'): 3, ...})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_dist = FreqDist(ngrams(lemlist,2))\n",
    "print(\"Information of bigrams: \\n\",bi_dist)\n",
    "bi_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequenct distribution for trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of trigrams:\n",
      " [('The', 'ABC', 'Murders'), ('ABC', 'Murders', '–'), ('Murders', '–', '1936'), ('–', '1936', 'The'), ('1936', 'The', 'Adventure'), ('The', 'Adventure', 'Christmas'), ('Adventure', 'Christmas', 'Pudding'), ('Christmas', 'Pudding', '–'), ('Pudding', '–', '1960'), ('–', '1960', 'After'), ('1960', 'After', 'Funeral'), ('After', 'Funeral', '('), ('Funeral', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Funerals'), ('know', 'Funerals', 'Fatal'), ('Funerals', 'Fatal', ')'), ('Fatal', ')', '–'), (')', '–', '1953'), ('–', '1953', 'And'), ('1953', 'And', 'Then'), ('And', 'Then', 'There'), ('Then', 'There', 'Were'), ('There', 'Were', 'None'), ('Were', 'None', '('), ('None', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Ten'), ('know', 'Ten', 'Little'), ('Ten', 'Little', 'Indians'), ('Little', 'Indians', 'Ten'), ('Indians', 'Ten', 'Little'), ('Ten', 'Little', 'Niggers'), ('Little', 'Niggers', '–'), ('Niggers', '–', '1939'), ('–', '1939', 'Appointment'), ('1939', 'Appointment', 'Death'), ('Appointment', 'Death', '–'), ('Death', '–', '1938'), ('–', '1938', 'At'), ('1938', 'At', 'Bertram'), ('At', 'Bertram', '’'), ('Bertram', '’', 'Hotel'), ('’', 'Hotel', '–'), ('Hotel', '–', '1965'), ('–', '1965', 'The'), ('1965', 'The', 'Big'), ('The', 'Big', 'Four'), ('Big', 'Four', '–'), ('Four', '–', '1927'), ('–', '1927', 'The'), ('1927', 'The', 'Body'), ('The', 'Body', 'Library'), ('Body', 'Library', '–'), ('Library', '–', '1942'), ('–', '1942', 'By'), ('1942', 'By', 'Pricking'), ('By', 'Pricking', 'Thumbs'), ('Pricking', 'Thumbs', '–'), ('Thumbs', '–', '1968'), ('–', '1968', 'Cards'), ('1968', 'Cards', 'Table'), ('Cards', 'Table', '–'), ('Table', '–', '1936'), ('–', '1936', 'A'), ('1936', 'A', 'Caribbean'), ('A', 'Caribbean', 'Mystery'), ('Caribbean', 'Mystery', '–'), ('Mystery', '–', '1964'), ('–', '1964', 'Cat'), ('1964', 'Cat', 'Among'), ('Cat', 'Among', 'Pigeons'), ('Among', 'Pigeons', '–'), ('Pigeons', '–', '1959'), ('–', '1959', 'The'), ('1959', 'The', 'Clocks'), ('The', 'Clocks', '–'), ('Clocks', '–', '1963'), ('–', '1963', 'Crooked'), ('1963', 'Crooked', 'House'), ('Crooked', 'House', '–'), ('House', '–', '1949'), ('–', '1949', 'Curtain'), ('1949', 'Curtain', ':'), ('Curtain', ':', 'Poirot'), (':', 'Poirot', '’'), ('Poirot', '’', 'Last'), ('’', 'Last', 'Case'), ('Last', 'Case', '–'), ('Case', '–', '1975'), ('–', '1975', 'Dead'), ('1975', 'Dead', 'Man'), ('Dead', 'Man', '’'), ('Man', '’', 'Folly'), ('’', 'Folly', '–'), ('Folly', '–', '1956'), ('–', '1956', 'Death'), ('1956', 'Death', 'Comes'), ('Death', 'Comes', 'At'), ('Comes', 'At', 'The'), ('At', 'The', 'End'), ('The', 'End', '–'), ('End', '–', '1945'), ('–', '1945', 'Death'), ('1945', 'Death', 'Clouds'), ('Death', 'Clouds', '('), ('Clouds', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Death'), ('know', 'Death', 'In'), ('Death', 'In', 'The'), ('In', 'The', 'Air'), ('The', 'Air', ')'), ('Air', ')', '–'), (')', '–', '1935'), ('–', '1935', 'Death'), ('1935', 'Death', 'Nile'), ('Death', 'Nile', '–'), ('Nile', '–', '1937'), ('–', '1937', 'Destination'), ('1937', 'Destination', 'Unknown'), ('Destination', 'Unknown', '('), ('Unknown', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'So'), ('know', 'So', 'Many'), ('So', 'Many', 'Steps'), ('Many', 'Steps', 'Death'), ('Steps', 'Death', ')'), ('Death', ')', '–'), (')', '–', '1954'), ('–', '1954', 'Double'), ('1954', 'Double', 'Sin'), ('Double', 'Sin', 'Other'), ('Sin', 'Other', 'Stories'), ('Other', 'Stories', '–'), ('Stories', '–', '1961'), ('–', '1961', 'Dumb'), ('1961', 'Dumb', 'Witness'), ('Dumb', 'Witness', '('), ('Witness', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Poirot'), ('know', 'Poirot', 'Loses'), ('Poirot', 'Loses', 'Client'), ('Loses', 'Client', ')'), ('Client', ')', '–'), (')', '–', '1937'), ('–', '1937', 'Elephants'), ('1937', 'Elephants', 'Can'), ('Elephants', 'Can', 'Remember'), ('Can', 'Remember', '–'), ('Remember', '–', '1972'), ('–', '1972', 'Endless'), ('1972', 'Endless', 'Night'), ('Endless', 'Night', '–'), ('Night', '–', '1967'), ('–', '1967', 'Evil'), ('1967', 'Evil', 'Under'), ('Evil', 'Under', 'Sun'), ('Under', 'Sun', '–'), ('Sun', '–', '1941'), ('–', '1941', 'Five'), ('1941', 'Five', 'Little'), ('Five', 'Little', 'Pigs'), ('Little', 'Pigs', '('), ('Pigs', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Murder'), ('know', 'Murder', 'In'), ('Murder', 'In', 'Retrospect'), ('In', 'Retrospect', ')'), ('Retrospect', ')', '–'), (')', '–', '1943'), ('–', '1943', '4.50'), ('1943', '4.50', 'Paddington'), ('4.50', 'Paddington', '('), ('Paddington', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'What'), ('know', 'What', 'Mrs.'), ('What', 'Mrs.', 'McGillicuty'), ('Mrs.', 'McGillicuty', 'Saw'), ('McGillicuty', 'Saw', ')'), ('Saw', ')', '–'), (')', '–', '1957'), ('–', '1957', 'The'), ('1957', 'The', 'Golden'), ('The', 'Golden', 'Ball'), ('Golden', 'Ball', 'Other'), ('Ball', 'Other', 'Stories'), ('Other', 'Stories', '–'), ('Stories', '–', '1971'), ('–', '1971', 'Halloween'), ('1971', 'Halloween', 'Party'), ('Halloween', 'Party', '–'), ('Party', '–', '1969'), ('–', '1969', 'Hercules'), ('1969', 'Hercules', 'Poirot'), ('Hercules', 'Poirot', '’'), ('Poirot', '’', 'Christmas'), ('’', 'Christmas', '('), ('Christmas', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'A'), ('know', 'A', 'Holiday'), ('A', 'Holiday', 'Murder'), ('Holiday', 'Murder', ')'), ('Murder', ')', '–'), (')', '–', '1938'), ('–', '1938', 'Hickory'), ('1938', 'Hickory', 'Dickory'), ('Hickory', 'Dickory', 'Death'), ('Dickory', 'Death', '–'), ('Death', '–', '1955'), ('–', '1955', 'The'), ('1955', 'The', 'Hollow'), ('The', 'Hollow', '('), ('Hollow', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Murder'), ('know', 'Murder', 'After'), ('Murder', 'After', 'Hours'), ('After', 'Hours', ')'), ('Hours', ')', '–'), (')', '–', '1946'), ('–', '1946', 'The'), ('1946', 'The', 'Hound'), ('The', 'Hound', 'Death'), ('Hound', 'Death', '–'), ('Death', '–', '1933'), ('–', '1933', 'The'), ('1933', 'The', 'Labours'), ('The', 'Labours', 'Hercules'), ('Labours', 'Hercules', '–'), ('Hercules', '–', '1947'), ('–', '1947', 'The'), ('1947', 'The', 'Listerdale'), ('The', 'Listerdale', 'Mystery'), ('Listerdale', 'Mystery', 'Morterblumen'), ('Mystery', 'Morterblumen', '–'), ('Morterblumen', '–', '1934'), ('–', '1934', 'Lord'), ('1934', 'Lord', 'Edgware'), ('Lord', 'Edgware', 'Dies'), ('Edgware', 'Dies', '('), ('Dies', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Thirteen'), ('know', 'Thirteen', 'At'), ('Thirteen', 'At', 'Dinner'), ('At', 'Dinner', ')'), ('Dinner', ')', '–'), (')', '–', '1933'), ('–', '1933', 'The'), ('1933', 'The', 'Man'), ('The', 'Man', 'Brown'), ('Man', 'Brown', 'Suit'), ('Brown', 'Suit', '('), ('Suit', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Mystery'), ('know', 'Mystery', 'Mill'), ('Mystery', 'Mill', 'House'), ('Mill', 'House', ')'), ('House', ')', '–'), (')', '–', '1924'), ('–', '1924', 'The'), ('1924', 'The', 'Mirror'), ('The', 'Mirror', 'Crack'), ('Mirror', 'Crack', '’'), ('Crack', '’', 'Side'), ('’', 'Side', 'Side'), ('Side', 'Side', '('), ('Side', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'The'), ('know', 'The', 'Mirror'), ('The', 'Mirror', 'Crack'), ('Mirror', 'Crack', '’'), ('Crack', '’', ')'), ('’', ')', '–'), (')', '–', '1962'), ('–', '1962', 'Miss'), ('1962', 'Miss', 'Marple'), ('Miss', 'Marple', '’'), ('Marple', '’', 'Final'), ('’', 'Final', 'Cases'), ('Final', 'Cases', '–'), ('Cases', '–', '1979'), ('–', '1979', 'The'), ('1979', 'The', 'Mousetrap'), ('The', 'Mousetrap', 'Other'), ('Mousetrap', 'Other', 'Stories'), ('Other', 'Stories', '('), ('Stories', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', '3'), ('know', '3', 'Blind'), ('3', 'Blind', 'Mice'), ('Blind', 'Mice', ')'), ('Mice', ')', '1950'), (')', '1950', 'The'), ('1950', 'The', 'Moving'), ('The', 'Moving', 'Finger'), ('Moving', 'Finger', '–'), ('Finger', '–', '1943'), ('–', '1943', 'Mrs.'), ('1943', 'Mrs.', 'McGinty'), ('Mrs.', 'McGinty', '’'), ('McGinty', '’', 'Dead'), ('’', 'Dead', '–'), ('Dead', '–', '1952'), ('–', '1952', 'The'), ('1952', 'The', 'Murder'), ('The', 'Murder', 'Vicarage'), ('Murder', 'Vicarage', '–'), ('Vicarage', '–', '1930'), ('–', '1930', 'Murder'), ('1930', 'Murder', 'Mesopotamia'), ('Murder', 'Mesopotamia', '–'), ('Mesopotamia', '–', '1936'), ('–', '1936', 'Murder'), ('1936', 'Murder', 'Mews'), ('Murder', 'Mews', '('), ('Mews', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Dead'), ('know', 'Dead', 'Man'), ('Dead', 'Man', '’'), ('Man', '’', 'Mirror'), ('’', 'Mirror', ')'), ('Mirror', ')', '–'), (')', '–', '1937'), ('–', '1937', 'A'), ('1937', 'A', 'Murder'), ('A', 'Murder', 'Announced'), ('Murder', 'Announced', '–'), ('Announced', '–', '1950'), ('–', '1950', 'Murder'), ('1950', 'Murder', 'Easy'), ('Murder', 'Easy', 'Easy'), ('Easy', 'Easy', 'Kill'), ('Easy', 'Kill', '–'), ('Kill', '–', '1939'), ('–', '1939', 'The'), ('1939', 'The', 'Murder'), ('The', 'Murder', 'Roger'), ('Murder', 'Roger', 'Ackroyd'), ('Roger', 'Ackroyd', '–'), ('Ackroyd', '–', '1926'), ('–', '1926', 'Murder'), ('1926', 'Murder', 'Links'), ('Murder', 'Links', '–'), ('Links', '–', '1923'), ('–', '1923', 'Murder'), ('1923', 'Murder', 'Orient'), ('Murder', 'Orient', 'Express'), ('Orient', 'Express', '('), ('Express', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Murder'), ('know', 'Murder', 'Calais'), ('Murder', 'Calais', 'Coach'), ('Calais', 'Coach', ')'), ('Coach', ')', '–'), (')', '–', '1934'), ('–', '1934', 'The'), ('1934', 'The', 'Mysterious'), ('The', 'Mysterious', 'Affair'), ('Mysterious', 'Affair', 'Styles'), ('Affair', 'Styles', '–'), ('Styles', '–', '1920'), ('–', '1920', 'The'), ('1920', 'The', 'Mysterious'), ('The', 'Mysterious', 'Mr.'), ('Mysterious', 'Mr.', 'Quin'), ('Mr.', 'Quin', '–'), ('Quin', '–', '1930'), ('–', '1930', 'The'), ('1930', 'The', 'Mystery'), ('The', 'Mystery', 'Blue'), ('Mystery', 'Blue', 'Train'), ('Blue', 'Train', '–'), ('Train', '–', '1928'), ('–', '1928', 'Nemesis'), ('1928', 'Nemesis', '–'), ('Nemesis', '–', '1971'), ('–', '1971', 'N'), ('1971', 'N', 'M'), ('N', 'M', '?'), ('M', '?', '–'), ('?', '–', '1941'), ('–', '1941', 'One'), ('1941', 'One', ','), ('One', ',', 'Two'), (',', 'Two', ','), ('Two', ',', 'Buckle'), (',', 'Buckle', 'My'), ('Buckle', 'My', 'Shoe'), ('My', 'Shoe', '('), ('Shoe', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'The'), ('know', 'The', 'Patriotic'), ('The', 'Patriotic', 'Murders'), ('Patriotic', 'Murders', ')'), ('Murders', ')', '–'), (')', '–', '1940'), ('–', '1940', 'Ordeal'), ('1940', 'Ordeal', 'Innocence'), ('Ordeal', 'Innocence', '–'), ('Innocence', '–', '1958'), ('–', '1958', 'The'), ('1958', 'The', 'Pale'), ('The', 'Pale', 'Horse'), ('Pale', 'Horse', '–'), ('Horse', '–', '1961'), ('–', '1961', 'Parker'), ('1961', 'Parker', 'Pyne'), ('Parker', 'Pyne', 'Investigates'), ('Pyne', 'Investigates', '('), ('Investigates', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Mr.'), ('know', 'Mr.', 'Parker'), ('Mr.', 'Parker', 'Pyne'), ('Parker', 'Pyne', ','), ('Pyne', ',', 'Detective'), (',', 'Detective', ')'), ('Detective', ')', '–'), (')', '–', '1934'), ('–', '1934', 'Partners'), ('1934', 'Partners', 'Crime'), ('Partners', 'Crime', '–'), ('Crime', '–', '1929'), ('–', '1929', 'Passenger'), ('1929', 'Passenger', 'Frankfurt'), ('Passenger', 'Frankfurt', '–'), ('Frankfurt', '–', '1970'), ('–', '1970', 'Peril'), ('1970', 'Peril', 'End'), ('Peril', 'End', 'House'), ('End', 'House', '–'), ('House', '–', '1932'), ('–', '1932', 'A'), ('1932', 'A', 'Pocket'), ('A', 'Pocket', 'Full'), ('Pocket', 'Full', 'Rye'), ('Full', 'Rye', '–'), ('Rye', '–', '1953'), ('–', '1953', 'Poirot'), ('1953', 'Poirot', 'Investigates'), ('Poirot', 'Investigates', '–'), ('Investigates', '–', '1924'), ('–', '1924', 'Poirot'), ('1924', 'Poirot', '’'), ('Poirot', '’', 'Early'), ('’', 'Early', 'Cases'), ('Early', 'Cases', '–'), ('Cases', '–', '1974'), ('–', '1974', 'Postern'), ('1974', 'Postern', 'Fate'), ('Postern', 'Fate', '–'), ('Fate', '–', '1973'), ('–', '1973', 'Problem'), ('1973', 'Problem', 'Pollensa'), ('Problem', 'Pollensa', 'Bay'), ('Pollensa', 'Bay', '–'), ('Bay', '–', '19'), ('–', '19', '?'), ('19', '?', '?'), ('?', '?', 'The'), ('?', 'The', 'Regatta'), ('The', 'Regatta', 'Mystery'), ('Regatta', 'Mystery', '–'), ('Mystery', '–', '1939'), ('–', '1939', 'Sad'), ('1939', 'Sad', 'Cypress'), ('Sad', 'Cypress', '–'), ('Cypress', '–', '1940'), ('–', '1940', 'The'), ('1940', 'The', 'Secret'), ('The', 'Secret', 'Adversary'), ('Secret', 'Adversary', '–'), ('Adversary', '–', '1922'), ('–', '1922', 'The'), ('1922', 'The', 'Secret'), ('The', 'Secret', 'Chimneys'), ('Secret', 'Chimneys', '–'), ('Chimneys', '–', '1925'), ('–', '1925', 'The'), ('1925', 'The', 'Seven'), ('The', 'Seven', 'Dials'), ('Seven', 'Dials', 'Mystery'), ('Dials', 'Mystery', '–'), ('Mystery', '–', '1929'), ('–', '1929', 'The'), ('1929', 'The', 'Sittaford'), ('The', 'Sittaford', 'Mystery'), ('Sittaford', 'Mystery', '('), ('Mystery', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'The'), ('know', 'The', 'Murder'), ('The', 'Murder', 'At'), ('Murder', 'At', 'Hazelmoor'), ('At', 'Hazelmoor', ')'), ('Hazelmoor', ')', '–'), (')', '–', '1931'), ('–', '1931', 'Sleeping'), ('1931', 'Sleeping', 'Murder'), ('Sleeping', 'Murder', '–'), ('Murder', '–', '1976'), ('–', '1976', 'Sparkling'), ('1976', 'Sparkling', 'Cyanide'), ('Sparkling', 'Cyanide', '('), ('Cyanide', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Remembered'), ('know', 'Remembered', 'Death'), ('Remembered', 'Death', ')'), ('Death', ')', '–'), (')', '–', '1945'), ('–', '1945', 'Taken'), ('1945', 'Taken', 'Flood'), ('Taken', 'Flood', '('), ('Flood', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'There'), ('know', 'There', 'Is'), ('There', 'Is', 'Tide…'), ('Is', 'Tide…', ')'), ('Tide…', ')', '–'), (')', '–', '1948'), ('–', '1948', 'They'), ('1948', 'They', 'Came'), ('They', 'Came', 'Baghdad'), ('Came', 'Baghdad', '–'), ('Baghdad', '–', '1951'), ('–', '1951', 'They'), ('1951', 'They', 'Do'), ('They', 'Do', 'It'), ('Do', 'It', 'With'), ('It', 'With', 'Mirrors'), ('With', 'Mirrors', '('), ('Mirrors', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Murder'), ('know', 'Murder', 'Mirrors'), ('Murder', 'Mirrors', ')'), ('Mirrors', ')', '–'), (')', '–', '1952'), ('–', '1952', 'Third'), ('1952', 'Third', 'Girl'), ('Third', 'Girl', '–'), ('Girl', '–', '1966'), ('–', '1966', 'The'), ('1966', 'The', 'Thirteen'), ('The', 'Thirteen', 'Problems'), ('Thirteen', 'Problems', '('), ('Problems', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'The'), ('know', 'The', 'Tuesday'), ('The', 'Tuesday', 'Club'), ('Tuesday', 'Club', 'Murders'), ('Club', 'Murders', '–'), ('Murders', '–', '1932'), ('–', '1932', 'Three-Act'), ('1932', 'Three-Act', 'Tragedy'), ('Three-Act', 'Tragedy', '('), ('Tragedy', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'Murder'), ('know', 'Murder', 'In'), ('Murder', 'In', 'Three'), ('In', 'Three', 'Acts'), ('Three', 'Acts', ')'), ('Acts', ')', '–'), (')', '–', '1935'), ('–', '1935', 'Towards'), ('1935', 'Towards', 'Zero'), ('Towards', 'Zero', '–'), ('Zero', '–', '1944'), ('–', '1944', 'The'), ('1944', 'The', 'Underdog'), ('The', 'Underdog', 'Other'), ('Underdog', 'Other', 'Stories'), ('Other', 'Stories', '–'), ('Stories', '–', '1951'), ('–', '1951', 'Witness'), ('1951', 'Witness', 'Prosecution'), ('Witness', 'Prosecution', 'Other'), ('Prosecution', 'Other', 'Stories'), ('Other', 'Stories', '–'), ('Stories', '–', '1948'), ('–', '1948', 'Why'), ('1948', 'Why', 'Didn'), ('Why', 'Didn', '’'), ('Didn', '’', 'They'), ('’', 'They', 'Ask'), ('They', 'Ask', 'Evans'), ('Ask', 'Evans', '('), ('Evans', '(', 'also'), ('(', 'also', 'know'), ('also', 'know', 'The'), ('know', 'The', 'Boomerang'), ('The', 'Boomerang', 'Clue'), ('Boomerang', 'Clue', ')'), ('Clue', ')', '–'), (')', '–', '1934')]\n"
     ]
    }
   ],
   "source": [
    "print(\"List of trigrams:\\n\",list(ngrams(lemlist,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution for trigrams using ngrams function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of trigrams: \n",
      " <FreqDist with 568 samples and 612 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({('(', 'also', 'know'): 24, ('also', 'know', 'Murder'): 5, ('also', 'know', 'The'): 5, ('Other', 'Stories', '–'): 4, (')', '–', '1934'): 3, ('Dead', 'Man', '’'): 2, (')', '–', '1935'): 2, ('Death', ')', '–'): 2, (')', '–', '1937'): 2, ('know', 'Murder', 'In'): 2, ...})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_dist = FreqDist(ngrams(lemlist,3))\n",
    "print(\"Information of trigrams: \\n\",tri_dist)\n",
    "tri_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
